{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching models from Hugging Face Hub...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1427it [02:27,  9.83it/s]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from datetime import datetime, timezone, timedelta\n",
    "import pandas as pd\n",
    "from huggingface_hub import HfApi, HfFolder\n",
    "\n",
    "\n",
    "# Constants\n",
    "MIN_DOWNLOADS = 100\n",
    "SINCE_DATE = datetime.now(timezone.utc) - timedelta(days=365*3)  # Collect models created in the last year\n",
    "OUTPUT_CSV = \"hf_models.csv\"\n",
    "OUTPUT_DIR = \"model_files\"  # Directory to save model files\n",
    "\n",
    "# Authentication (optional)\n",
    "ACCESS_TOKEN = os.getenv(\"HF_ACCESS_TOKEN\")  # Set your Hugging Face API token as an environment variable\n",
    "\n",
    "# Initialize API\n",
    "api = HfApi()\n",
    "\n",
    "# If you have an access token, save it\n",
    "if ACCESS_TOKEN:\n",
    "    HfFolder.save_token(ACCESS_TOKEN)\n",
    "\n",
    "# Function to collect model data\n",
    "def collect_model_data():\n",
    "    models_data = []\n",
    "    fetch_limit = 10000  # Maximum number of models to fetch\n",
    "    sort_order = \"downloads\"  # You can sort by 'lastModified', 'downloads', 'stars', etc.\n",
    "\n",
    "    # Note: As of my knowledge cutoff in 2021, the Hugging Face Hub API does not support filtering by creation date directly.\n",
    "    # We'll fetch models and filter them manually.\n",
    "\n",
    "    # Search models\n",
    "    print(\"Fetching models from Hugging Face Hub...\")\n",
    "    models = api.list_models(\n",
    "        sort=sort_order,\n",
    "        direction=-1,  # Descending order\n",
    "        limit=fetch_limit,\n",
    "        use_auth_token=ACCESS_TOKEN,\n",
    "        full=True,  # Fetch full metadata\n",
    "        \n",
    "    )\n",
    "    from tqdm import tqdm\n",
    "    for model in tqdm(models):\n",
    "        # Convert timestamp strings to datetime objects\n",
    "        if hasattr(model, 'lastModified'):\n",
    "            last_modified = model.lastModified\n",
    "        else:\n",
    "            last_modified = datetime.now(tz=model.lastModified.tzinfo)\n",
    "\n",
    "        # Filter models created since the specified date\n",
    "        if last_modified >= SINCE_DATE:\n",
    "            # Get the model's downloads (may require an authenticated request)\n",
    "            downloads = model.downloads if hasattr(model, 'downloads') else 0\n",
    "\n",
    "            if downloads >= MIN_DOWNLOADS:\n",
    "                model_data = {\n",
    "                    \"modelId\": model.modelId,\n",
    "                    \"modelName\": model.modelId.split(\"/\")[-1],\n",
    "                    \"author\": model.modelId.split(\"/\")[0] if \"/\" in model.modelId else None,\n",
    "                    \"downloads\": downloads,\n",
    "                    \"lastModified\": model.lastModified,\n",
    "                    \"tags\": model.tags,\n",
    "                    \"pipeline_tag\": model.pipeline_tag,\n",
    "                    \"sha\": model.sha,\n",
    "                    \"private\": model.private,\n",
    "                    \"inference\": model.inference,\n",
    "\n",
    "                }\n",
    "                models_data.append(model_data)\n",
    "\n",
    "        # Respect rate limits\n",
    "        time.sleep(0.1)\n",
    "\n",
    "    print(f\"Total models collected: {len(models_data)}\")\n",
    "    return pd.DataFrame(models_data)\n",
    "\n",
    "# Optional: Function to download model files\n",
    "# def download_model_files(model_ids):\n",
    "#     if not os.path.exists(OUTPUT_DIR):\n",
    "#         os.makedirs(OUTPUT_DIR)\n",
    "\n",
    "#     for model_id in model_ids:\n",
    "#         print(f\"Downloading files for model: {model_id}\")\n",
    "#         files = api.list_repo_files(repo_id=model_id, use_auth_token=ACCESS_TOKEN)\n",
    "\n",
    "#         # Create a directory for each model\n",
    "#         model_dir = os.path.join(OUTPUT_DIR, model_id.replace(\"/\", \"_\"))\n",
    "#         if not os.path.exists(model_dir):\n",
    "#             os.makedirs(model_dir)\n",
    "\n",
    "#         for file_name in files:\n",
    "#             # Download each file\n",
    "#             file_path = os.path.join(model_dir, file_name)\n",
    "#             api.download_file(\n",
    "#                 repo_id=model_id,\n",
    "#                 filename=file_name,\n",
    "#                 local_dir=model_dir,\n",
    "#                 use_auth_token=ACCESS_TOKEN,\n",
    "#             )\n",
    "\n",
    "#         # Respect rate limits\n",
    "#         time.sleep(0.5)\n",
    "\n",
    "df = collect_model_data()\n",
    "\n",
    "df.to_csv(OUTPUT_CSV, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modelId</th>\n",
       "      <th>modelName</th>\n",
       "      <th>author</th>\n",
       "      <th>downloads</th>\n",
       "      <th>lastModified</th>\n",
       "      <th>tags</th>\n",
       "      <th>pipeline_tag</th>\n",
       "      <th>sha</th>\n",
       "      <th>private</th>\n",
       "      <th>inference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MIT/ast-finetuned-audioset-10-10-0.4593</td>\n",
       "      <td>ast-finetuned-audioset-10-10-0.4593</td>\n",
       "      <td>MIT</td>\n",
       "      <td>189285567</td>\n",
       "      <td>2023-09-06 14:49:15+00:00</td>\n",
       "      <td>[transformers, pytorch, safetensors, audio-spe...</td>\n",
       "      <td>audio-classification</td>\n",
       "      <td>f826b80d28226b62986cc218e5cec390b1096902</td>\n",
       "      <td>False</td>\n",
       "      <td>cold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>google-bert/bert-base-uncased</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>google-bert</td>\n",
       "      <td>61903514</td>\n",
       "      <td>2024-02-19 11:06:12+00:00</td>\n",
       "      <td>[transformers, pytorch, tf, jax, rust, coreml,...</td>\n",
       "      <td>fill-mask</td>\n",
       "      <td>86b5e0934494bd15c9632b12f734a8a67f723594</td>\n",
       "      <td>False</td>\n",
       "      <td>loading</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sentence-transformers/all-MiniLM-L6-v2</td>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "      <td>sentence-transformers</td>\n",
       "      <td>46030976</td>\n",
       "      <td>2024-05-29 14:43:28+00:00</td>\n",
       "      <td>[sentence-transformers, pytorch, tf, rust, onn...</td>\n",
       "      <td>sentence-similarity</td>\n",
       "      <td>8b3219a92973c328a8e22fadcfa821b5dc75636a</td>\n",
       "      <td>False</td>\n",
       "      <td>warm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>google/vit-base-patch16-224-in21k</td>\n",
       "      <td>vit-base-patch16-224-in21k</td>\n",
       "      <td>google</td>\n",
       "      <td>35397121</td>\n",
       "      <td>2024-02-05 16:37:39+00:00</td>\n",
       "      <td>[transformers, pytorch, tf, jax, safetensors, ...</td>\n",
       "      <td>image-feature-extraction</td>\n",
       "      <td>b4569560a39a0f1af58e3ddaf17facf20ab919b0</td>\n",
       "      <td>False</td>\n",
       "      <td>explicit-opt-out</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>openai/clip-vit-large-patch14</td>\n",
       "      <td>clip-vit-large-patch14</td>\n",
       "      <td>openai</td>\n",
       "      <td>32383367</td>\n",
       "      <td>2023-09-15 15:49:35+00:00</td>\n",
       "      <td>[transformers, pytorch, tf, jax, safetensors, ...</td>\n",
       "      <td>zero-shot-image-classification</td>\n",
       "      <td>32bd64288804d66eefd0ccbe215aa642df71cc41</td>\n",
       "      <td>False</td>\n",
       "      <td>cold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>amazon/chronos-t5-tiny</td>\n",
       "      <td>chronos-t5-tiny</td>\n",
       "      <td>amazon</td>\n",
       "      <td>30094073</td>\n",
       "      <td>2024-05-13 21:09:18+00:00</td>\n",
       "      <td>[transformers, safetensors, t5, text2text-gene...</td>\n",
       "      <td>time-series-forecasting</td>\n",
       "      <td>d968d90a73cc4e3a3103e262d1d895204e74e415</td>\n",
       "      <td>False</td>\n",
       "      <td>pipeline-library-pair-not-supported</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>openai/clip-vit-base-patch32</td>\n",
       "      <td>clip-vit-base-patch32</td>\n",
       "      <td>openai</td>\n",
       "      <td>26576499</td>\n",
       "      <td>2024-02-29 09:45:55+00:00</td>\n",
       "      <td>[transformers, pytorch, tf, jax, clip, zero-sh...</td>\n",
       "      <td>zero-shot-image-classification</td>\n",
       "      <td>3d74acf9a28c67741b2f4f2ea7635f0aaf6f0268</td>\n",
       "      <td>False</td>\n",
       "      <td>warm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1231czx/llama3_it_ultra_list_and_bold500</td>\n",
       "      <td>llama3_it_ultra_list_and_bold500</td>\n",
       "      <td>1231czx</td>\n",
       "      <td>25414501</td>\n",
       "      <td>2024-09-03 12:58:12+00:00</td>\n",
       "      <td>[transformers, safetensors, llama, text-classi...</td>\n",
       "      <td>text-classification</td>\n",
       "      <td>31bbdb84c8c535f807fad9013a50b71a924a7fc2</td>\n",
       "      <td>False</td>\n",
       "      <td>cold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>jonatasgrosman/wav2vec2-large-xlsr-53-english</td>\n",
       "      <td>wav2vec2-large-xlsr-53-english</td>\n",
       "      <td>jonatasgrosman</td>\n",
       "      <td>21263718</td>\n",
       "      <td>2023-03-25 10:56:55+00:00</td>\n",
       "      <td>[transformers, pytorch, jax, safetensors, wav2...</td>\n",
       "      <td>automatic-speech-recognition</td>\n",
       "      <td>569a6236e92bd5f7652a0420bfe9bb94c5664080</td>\n",
       "      <td>False</td>\n",
       "      <td>cold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>FacebookAI/xlm-roberta-large</td>\n",
       "      <td>xlm-roberta-large</td>\n",
       "      <td>FacebookAI</td>\n",
       "      <td>21028349</td>\n",
       "      <td>2024-02-19 12:48:30+00:00</td>\n",
       "      <td>[transformers, pytorch, tf, jax, onnx, safeten...</td>\n",
       "      <td>fill-mask</td>\n",
       "      <td>c23d21b0620b635a76227c604d44e43a9f0ee389</td>\n",
       "      <td>False</td>\n",
       "      <td>warm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>openai/clip-vit-base-patch16</td>\n",
       "      <td>clip-vit-base-patch16</td>\n",
       "      <td>openai</td>\n",
       "      <td>19432048</td>\n",
       "      <td>2022-10-04 09:42:28+00:00</td>\n",
       "      <td>[transformers, pytorch, jax, clip, zero-shot-i...</td>\n",
       "      <td>zero-shot-image-classification</td>\n",
       "      <td>57c216476eefef5ab752ec549e440a49ae4ae5f3</td>\n",
       "      <td>False</td>\n",
       "      <td>cold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>mixedbread-ai/mxbai-embed-large-v1</td>\n",
       "      <td>mxbai-embed-large-v1</td>\n",
       "      <td>mixedbread-ai</td>\n",
       "      <td>17113076</td>\n",
       "      <td>2024-09-17 08:24:14+00:00</td>\n",
       "      <td>[sentence-transformers, onnx, safetensors, ggu...</td>\n",
       "      <td>feature-extraction</td>\n",
       "      <td>526dc52cb738085d87002bf00ca4d3d99fd0029b</td>\n",
       "      <td>False</td>\n",
       "      <td>warm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sentence-transformers/all-mpnet-base-v2</td>\n",
       "      <td>all-mpnet-base-v2</td>\n",
       "      <td>sentence-transformers</td>\n",
       "      <td>15139402</td>\n",
       "      <td>2024-03-27 09:46:22+00:00</td>\n",
       "      <td>[sentence-transformers, pytorch, safetensors, ...</td>\n",
       "      <td>sentence-similarity</td>\n",
       "      <td>84f2bcc00d77236f9e89c8a360a00fb1139bf47d</td>\n",
       "      <td>False</td>\n",
       "      <td>loading</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>distilbert/distilbert-base-uncased</td>\n",
       "      <td>distilbert-base-uncased</td>\n",
       "      <td>distilbert</td>\n",
       "      <td>13328383</td>\n",
       "      <td>2024-05-06 13:44:53+00:00</td>\n",
       "      <td>[transformers, pytorch, tf, jax, rust, safeten...</td>\n",
       "      <td>fill-mask</td>\n",
       "      <td>12040accade4e8a0f71eabdb258fecc2e7e948be</td>\n",
       "      <td>False</td>\n",
       "      <td>warm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>timm/resnet50.a1_in1k</td>\n",
       "      <td>resnet50.a1_in1k</td>\n",
       "      <td>timm</td>\n",
       "      <td>13263083</td>\n",
       "      <td>2024-02-10 23:39:02+00:00</td>\n",
       "      <td>[timm, pytorch, safetensors, image-classificat...</td>\n",
       "      <td>image-classification</td>\n",
       "      <td>5d9e13b8fdab4d9718bcf2c8f5c3af01878367e8</td>\n",
       "      <td>False</td>\n",
       "      <td>cold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>FacebookAI/roberta-base</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>FacebookAI</td>\n",
       "      <td>13151095</td>\n",
       "      <td>2024-02-19 12:39:28+00:00</td>\n",
       "      <td>[transformers, pytorch, tf, jax, rust, safeten...</td>\n",
       "      <td>fill-mask</td>\n",
       "      <td>e2da8e2f811d1448a5b465c236feacd80ffbac7b</td>\n",
       "      <td>False</td>\n",
       "      <td>cold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>FacebookAI/xlm-roberta-base</td>\n",
       "      <td>xlm-roberta-base</td>\n",
       "      <td>FacebookAI</td>\n",
       "      <td>11449282</td>\n",
       "      <td>2024-02-19 12:48:21+00:00</td>\n",
       "      <td>[transformers, pytorch, tf, jax, onnx, safeten...</td>\n",
       "      <td>fill-mask</td>\n",
       "      <td>e73636d4f797dec63c3081bb6ed5c7b0bb3f2089</td>\n",
       "      <td>False</td>\n",
       "      <td>loading</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>pyannote/segmentation-3.0</td>\n",
       "      <td>segmentation-3.0</td>\n",
       "      <td>pyannote</td>\n",
       "      <td>11340668</td>\n",
       "      <td>2024-05-10 19:35:46+00:00</td>\n",
       "      <td>[pyannote-audio, pytorch, pyannote, pyannote-a...</td>\n",
       "      <td>voice-activity-detection</td>\n",
       "      <td>e66f3d3b9eb0873085418a7b813d3b369bf160bb</td>\n",
       "      <td>False</td>\n",
       "      <td>explicit-opt-out</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>distilbert/distilbert-base-uncased-finetuned-s...</td>\n",
       "      <td>distilbert-base-uncased-finetuned-sst-2-english</td>\n",
       "      <td>distilbert</td>\n",
       "      <td>9481977</td>\n",
       "      <td>2023-12-19 16:29:37+00:00</td>\n",
       "      <td>[transformers, pytorch, tf, rust, onnx, safete...</td>\n",
       "      <td>text-classification</td>\n",
       "      <td>714eb0fa89d2f80546fda750413ed43d93601a13</td>\n",
       "      <td>False</td>\n",
       "      <td>cold</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              modelId  \\\n",
       "0             MIT/ast-finetuned-audioset-10-10-0.4593   \n",
       "1                       google-bert/bert-base-uncased   \n",
       "2              sentence-transformers/all-MiniLM-L6-v2   \n",
       "3                   google/vit-base-patch16-224-in21k   \n",
       "4                       openai/clip-vit-large-patch14   \n",
       "5                              amazon/chronos-t5-tiny   \n",
       "6                        openai/clip-vit-base-patch32   \n",
       "7            1231czx/llama3_it_ultra_list_and_bold500   \n",
       "8       jonatasgrosman/wav2vec2-large-xlsr-53-english   \n",
       "9                        FacebookAI/xlm-roberta-large   \n",
       "10                       openai/clip-vit-base-patch16   \n",
       "11                 mixedbread-ai/mxbai-embed-large-v1   \n",
       "12            sentence-transformers/all-mpnet-base-v2   \n",
       "13                 distilbert/distilbert-base-uncased   \n",
       "14                              timm/resnet50.a1_in1k   \n",
       "15                            FacebookAI/roberta-base   \n",
       "16                        FacebookAI/xlm-roberta-base   \n",
       "17                          pyannote/segmentation-3.0   \n",
       "18  distilbert/distilbert-base-uncased-finetuned-s...   \n",
       "\n",
       "                                          modelName                 author  \\\n",
       "0               ast-finetuned-audioset-10-10-0.4593                    MIT   \n",
       "1                                 bert-base-uncased            google-bert   \n",
       "2                                  all-MiniLM-L6-v2  sentence-transformers   \n",
       "3                        vit-base-patch16-224-in21k                 google   \n",
       "4                            clip-vit-large-patch14                 openai   \n",
       "5                                   chronos-t5-tiny                 amazon   \n",
       "6                             clip-vit-base-patch32                 openai   \n",
       "7                  llama3_it_ultra_list_and_bold500                1231czx   \n",
       "8                    wav2vec2-large-xlsr-53-english         jonatasgrosman   \n",
       "9                                 xlm-roberta-large             FacebookAI   \n",
       "10                            clip-vit-base-patch16                 openai   \n",
       "11                             mxbai-embed-large-v1          mixedbread-ai   \n",
       "12                                all-mpnet-base-v2  sentence-transformers   \n",
       "13                          distilbert-base-uncased             distilbert   \n",
       "14                                 resnet50.a1_in1k                   timm   \n",
       "15                                     roberta-base             FacebookAI   \n",
       "16                                 xlm-roberta-base             FacebookAI   \n",
       "17                                 segmentation-3.0               pyannote   \n",
       "18  distilbert-base-uncased-finetuned-sst-2-english             distilbert   \n",
       "\n",
       "    downloads              lastModified  \\\n",
       "0   189285567 2023-09-06 14:49:15+00:00   \n",
       "1    61903514 2024-02-19 11:06:12+00:00   \n",
       "2    46030976 2024-05-29 14:43:28+00:00   \n",
       "3    35397121 2024-02-05 16:37:39+00:00   \n",
       "4    32383367 2023-09-15 15:49:35+00:00   \n",
       "5    30094073 2024-05-13 21:09:18+00:00   \n",
       "6    26576499 2024-02-29 09:45:55+00:00   \n",
       "7    25414501 2024-09-03 12:58:12+00:00   \n",
       "8    21263718 2023-03-25 10:56:55+00:00   \n",
       "9    21028349 2024-02-19 12:48:30+00:00   \n",
       "10   19432048 2022-10-04 09:42:28+00:00   \n",
       "11   17113076 2024-09-17 08:24:14+00:00   \n",
       "12   15139402 2024-03-27 09:46:22+00:00   \n",
       "13   13328383 2024-05-06 13:44:53+00:00   \n",
       "14   13263083 2024-02-10 23:39:02+00:00   \n",
       "15   13151095 2024-02-19 12:39:28+00:00   \n",
       "16   11449282 2024-02-19 12:48:21+00:00   \n",
       "17   11340668 2024-05-10 19:35:46+00:00   \n",
       "18    9481977 2023-12-19 16:29:37+00:00   \n",
       "\n",
       "                                                 tags  \\\n",
       "0   [transformers, pytorch, safetensors, audio-spe...   \n",
       "1   [transformers, pytorch, tf, jax, rust, coreml,...   \n",
       "2   [sentence-transformers, pytorch, tf, rust, onn...   \n",
       "3   [transformers, pytorch, tf, jax, safetensors, ...   \n",
       "4   [transformers, pytorch, tf, jax, safetensors, ...   \n",
       "5   [transformers, safetensors, t5, text2text-gene...   \n",
       "6   [transformers, pytorch, tf, jax, clip, zero-sh...   \n",
       "7   [transformers, safetensors, llama, text-classi...   \n",
       "8   [transformers, pytorch, jax, safetensors, wav2...   \n",
       "9   [transformers, pytorch, tf, jax, onnx, safeten...   \n",
       "10  [transformers, pytorch, jax, clip, zero-shot-i...   \n",
       "11  [sentence-transformers, onnx, safetensors, ggu...   \n",
       "12  [sentence-transformers, pytorch, safetensors, ...   \n",
       "13  [transformers, pytorch, tf, jax, rust, safeten...   \n",
       "14  [timm, pytorch, safetensors, image-classificat...   \n",
       "15  [transformers, pytorch, tf, jax, rust, safeten...   \n",
       "16  [transformers, pytorch, tf, jax, onnx, safeten...   \n",
       "17  [pyannote-audio, pytorch, pyannote, pyannote-a...   \n",
       "18  [transformers, pytorch, tf, rust, onnx, safete...   \n",
       "\n",
       "                      pipeline_tag                                       sha  \\\n",
       "0             audio-classification  f826b80d28226b62986cc218e5cec390b1096902   \n",
       "1                        fill-mask  86b5e0934494bd15c9632b12f734a8a67f723594   \n",
       "2              sentence-similarity  8b3219a92973c328a8e22fadcfa821b5dc75636a   \n",
       "3         image-feature-extraction  b4569560a39a0f1af58e3ddaf17facf20ab919b0   \n",
       "4   zero-shot-image-classification  32bd64288804d66eefd0ccbe215aa642df71cc41   \n",
       "5          time-series-forecasting  d968d90a73cc4e3a3103e262d1d895204e74e415   \n",
       "6   zero-shot-image-classification  3d74acf9a28c67741b2f4f2ea7635f0aaf6f0268   \n",
       "7              text-classification  31bbdb84c8c535f807fad9013a50b71a924a7fc2   \n",
       "8     automatic-speech-recognition  569a6236e92bd5f7652a0420bfe9bb94c5664080   \n",
       "9                        fill-mask  c23d21b0620b635a76227c604d44e43a9f0ee389   \n",
       "10  zero-shot-image-classification  57c216476eefef5ab752ec549e440a49ae4ae5f3   \n",
       "11              feature-extraction  526dc52cb738085d87002bf00ca4d3d99fd0029b   \n",
       "12             sentence-similarity  84f2bcc00d77236f9e89c8a360a00fb1139bf47d   \n",
       "13                       fill-mask  12040accade4e8a0f71eabdb258fecc2e7e948be   \n",
       "14            image-classification  5d9e13b8fdab4d9718bcf2c8f5c3af01878367e8   \n",
       "15                       fill-mask  e2da8e2f811d1448a5b465c236feacd80ffbac7b   \n",
       "16                       fill-mask  e73636d4f797dec63c3081bb6ed5c7b0bb3f2089   \n",
       "17        voice-activity-detection  e66f3d3b9eb0873085418a7b813d3b369bf160bb   \n",
       "18             text-classification  714eb0fa89d2f80546fda750413ed43d93601a13   \n",
       "\n",
       "    private                            inference  \n",
       "0     False                                 cold  \n",
       "1     False                              loading  \n",
       "2     False                                 warm  \n",
       "3     False                     explicit-opt-out  \n",
       "4     False                                 cold  \n",
       "5     False  pipeline-library-pair-not-supported  \n",
       "6     False                                 warm  \n",
       "7     False                                 cold  \n",
       "8     False                                 cold  \n",
       "9     False                                 warm  \n",
       "10    False                                 cold  \n",
       "11    False                                 warm  \n",
       "12    False                              loading  \n",
       "13    False                                 warm  \n",
       "14    False                                 cold  \n",
       "15    False                                 cold  \n",
       "16    False                              loading  \n",
       "17    False                     explicit-opt-out  \n",
       "18    False                                 cold  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
