{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "import urllib.parse\n",
    "import os\n",
    "\n",
    "os.environ[\"GITHUB_ACCESS_TOKEN\"] = GITHUB_ACCESS_TOKEN\n",
    "os.environ[\"HUGGINGFACE_ACCESS_TOKEN\"] = HUGGINGFACE_ACCESS_TOKEN\n",
    "\n",
    "\n",
    "\n",
    "keywords = {\n",
    "  \"keywords\": {\n",
    "    \"getting-started\": {\n",
    "      \"gh-header-keywords\": [\n",
    "        \"getting started\",\n",
    "        \"installation\",\n",
    "        \"quick start\",\n",
    "        \"quickstart\",\n",
    "        \"setup\",\n",
    "        \"usage\",\n",
    "        \"example\",\n",
    "        \"demo\"\n",
    "      ],\n",
    "      \"hf-header-keywords\": [\n",
    "        \"how to use\",\n",
    "        \"usage\",\n",
    "        \"inference\",\n",
    "        \"example usage\",\n",
    "        \"sample code\",\n",
    "        \"model usage\",\n",
    "        \"usage example\"\n",
    "      ],\n",
    "      \"gh-content-keywords\": [\n",
    "        \"install\",\n",
    "        \"pip\",\n",
    "        \"requirements\",\n",
    "        \"dependency\",\n",
    "        \"clone\",\n",
    "        \"git clone\",\n",
    "        \"build\",\n",
    "        \"run\",\n",
    "        \"execute\",\n",
    "        \"usage\",\n",
    "        \"command line\",\n",
    "        \"code snippet\",\n",
    "        \"environment\",\n",
    "        \"virtualenv\",\n",
    "        \"conda\",\n",
    "        \"script\",\n",
    "        \"examples\",\n",
    "        \"usage instructions\",\n",
    "        \"dependencies\",\n",
    "        \"install instructions\"\n",
    "      ],\n",
    "      \"hf-content-keywords\": [\n",
    "        \"import\",\n",
    "        \"from transformers import\",\n",
    "        \"pipeline\",\n",
    "        \"tokenizer\",\n",
    "        \"model\",\n",
    "        \"generate\",\n",
    "        \"inference\",\n",
    "        \"code snippet\",\n",
    "        \"PyTorch\",\n",
    "        \"TensorFlow\",\n",
    "        \"example\",\n",
    "        \"Hugging Face Hub\",\n",
    "        \"task\",\n",
    "        \"fine-tune\",\n",
    "        \"load model\",\n",
    "        \"preprocess\",\n",
    "        \"prompt\",\n",
    "        \"output\",\n",
    "        \"usage example\",\n",
    "        \"inference example\"\n",
    "      ]\n",
    "    },\n",
    "    \"contributing\": {\n",
    "      \"gh-header-keywords\": [\n",
    "        \"contributing\",\n",
    "        \"contribution\",\n",
    "        \"contribute\",\n",
    "        \"pull request\",\n",
    "        \"bug report\",\n",
    "        \"issue\"\n",
    "      ],\n",
    "      \"hf-header-keywords\": [\n",
    "        \"how to contribute\",\n",
    "        \"contribute\",\n",
    "        \"report issues\",\n",
    "        \"feedback\",\n",
    "        \"suggestions\",\n",
    "        \"contact\",\n",
    "        \"collaborate\",\n",
    "        \"acknowledgements\"\n",
    "      ],\n",
    "      \"gh-content-keywords\": [\n",
    "        \"fork\",\n",
    "        \"pull request\",\n",
    "        \"issue tracker\",\n",
    "        \"guidelines\",\n",
    "        \"code style\",\n",
    "        \"testing\",\n",
    "        \"documentation\",\n",
    "        \"contributing guide\",\n",
    "        \"report bugs\",\n",
    "        \"feature requests\",\n",
    "        \"collaboration\",\n",
    "        \"development\",\n",
    "        \"submit\",\n",
    "        \"branch\",\n",
    "        \"merge\",\n",
    "        \"code review\",\n",
    "        \"community\",\n",
    "        \"issues\",\n",
    "        \"bug reports\",\n",
    "        \"commit\"\n",
    "      ],\n",
    "      \"hf-content-keywords\": [\n",
    "        \"issues\",\n",
    "        \"contact\",\n",
    "        \"suggestions\",\n",
    "        \"improvements\",\n",
    "        \"collaboration\",\n",
    "        \"email\",\n",
    "        \"open an issue\",\n",
    "        \"feedback\",\n",
    "        \"bug report\",\n",
    "        \"help\",\n",
    "        \"reach out\",\n",
    "        \"community\",\n",
    "        \"discussion\",\n",
    "        \"contribution\",\n",
    "        \"pull request\",\n",
    "        \"modify\",\n",
    "        \"enhance\",\n",
    "        \"questions\",\n",
    "        \"support\",\n",
    "        \"contact author\"\n",
    "      ]\n",
    "    },\n",
    "    \"license\": {\n",
    "      \"gh-header-keywords\": [\n",
    "        \"license\",\n",
    "        \"licence\",\n",
    "        \"copy right\"\n",
    "      ],\n",
    "      \"hf-header-keywords\": [\n",
    "        \"license\",\n",
    "        \"licence\",\n",
    "        \"copyright\",\n",
    "        \"terms\",\n",
    "        \"usage terms\",\n",
    "        \"legal\",\n",
    "        \"rights\"\n",
    "      ],\n",
    "      \"gh-content-keywords\": [\n",
    "        \"MIT\",\n",
    "        \"Apache\",\n",
    "        \"GPL\",\n",
    "        \"BSD\",\n",
    "        \"terms\",\n",
    "        \"conditions\",\n",
    "        \"distribution\",\n",
    "        \"modification\",\n",
    "        \"use\",\n",
    "        \"commercial use\",\n",
    "        \"liability\",\n",
    "        \"warranty\",\n",
    "        \"limitations\",\n",
    "        \"rights\",\n",
    "        \"reproduction\",\n",
    "        \"software license\",\n",
    "        \"license text\",\n",
    "        \"open source\",\n",
    "        \"copying\",\n",
    "        \"proprietary\"\n",
    "      ],\n",
    "      \"hf-content-keywords\": [\n",
    "        \"MIT\",\n",
    "        \"Apache\",\n",
    "        \"BSD\",\n",
    "        \"GPL\",\n",
    "        \"terms\",\n",
    "        \"conditions\",\n",
    "        \"use\",\n",
    "        \"limitations\",\n",
    "        \"copyright\",\n",
    "        \"redistribution\",\n",
    "        \"open source\",\n",
    "        \"commercial use\",\n",
    "        \"non-commercial\",\n",
    "        \"Creative Commons\",\n",
    "        \"CC BY\",\n",
    "        \"license text\",\n",
    "        \"restrictions\",\n",
    "        \"public domain\",\n",
    "        \"responsibility\",\n",
    "        \"liability\"\n",
    "      ]\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "# Constants\n",
    "GITHUB_API_URL = \"https://api.github.com\"\n",
    "PER_PAGE = 100  # Maximum allowed by GitHub API\n",
    "ACCESS_TOKEN = os.getenv(\"GITHUB_ACCESS_TOKEN\")  # Set your GitHub access token\n",
    "TOPICS = [\"data-science\", \"machine-learning\", \"ai\", \"api\", \"python\",\"pytorch\",\"data-science\",\"computer-vision\", \"tensorflow\", \"llm\", \"artificial-intelligence\"]  # Replace with your topics [\"nlp\"]\n",
    "MIN_STAR = 90  # Define your minimum star count threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing topic: data-science\n",
      "Total repositories found: 4211. Total pages: 10\n",
      "Completed page 1/10 for topic data-science with stars upper limit 500000\n",
      "Completed page 2/10 for topic data-science with stars upper limit 500000\n",
      "Completed page 3/10 for topic data-science with stars upper limit 500000\n",
      "Completed page 4/10 for topic data-science with stars upper limit 500000\n",
      "Reached repositories with stars less than 90. Moving to next topic.\n",
      "Finished processing topic: data-science\n",
      "Processing topic: machine-learning\n",
      "Total repositories found: 16174. Total pages: 10\n",
      "Completed page 1/10 for topic machine-learning with stars upper limit 500000\n",
      "Completed page 2/10 for topic machine-learning with stars upper limit 500000\n",
      "Completed page 3/10 for topic machine-learning with stars upper limit 500000\n",
      "Completed page 4/10 for topic machine-learning with stars upper limit 500000\n",
      "Completed page 5/10 for topic machine-learning with stars upper limit 500000\n",
      "Completed page 6/10 for topic machine-learning with stars upper limit 500000\n",
      "Completed page 7/10 for topic machine-learning with stars upper limit 500000\n",
      "Completed page 8/10 for topic machine-learning with stars upper limit 500000\n",
      "Completed page 9/10 for topic machine-learning with stars upper limit 500000\n",
      "Completed page 10/10 for topic machine-learning with stars upper limit 500000\n",
      "Adjusting stars upper limit to 312 and continuing.\n",
      "Total repositories found: 15170. Total pages: 10\n",
      "Completed page 1/10 for topic machine-learning with stars upper limit 312\n",
      "Completed page 2/10 for topic machine-learning with stars upper limit 312\n",
      "Completed page 3/10 for topic machine-learning with stars upper limit 312\n",
      "Completed page 4/10 for topic machine-learning with stars upper limit 312\n",
      "Completed page 5/10 for topic machine-learning with stars upper limit 312\n",
      "Completed page 6/10 for topic machine-learning with stars upper limit 312\n",
      "Completed page 7/10 for topic machine-learning with stars upper limit 312\n",
      "Completed page 8/10 for topic machine-learning with stars upper limit 312\n",
      "Reached repositories with stars less than 90. Moving to next topic.\n",
      "Finished processing topic: machine-learning\n",
      "Processing topic: ai\n",
      "Total repositories found: 8351. Total pages: 10\n",
      "Completed page 1/10 for topic ai with stars upper limit 500000\n",
      "Completed page 2/10 for topic ai with stars upper limit 500000\n",
      "Completed page 3/10 for topic ai with stars upper limit 500000\n",
      "Completed page 4/10 for topic ai with stars upper limit 500000\n",
      "Completed page 5/10 for topic ai with stars upper limit 500000\n",
      "Completed page 6/10 for topic ai with stars upper limit 500000\n",
      "Completed page 7/10 for topic ai with stars upper limit 500000\n",
      "Reached repositories with stars less than 90. Moving to next topic.\n",
      "Finished processing topic: ai\n",
      "Processing topic: api\n",
      "Total repositories found: 8235. Total pages: 10\n",
      "Completed page 1/10 for topic api with stars upper limit 500000\n",
      "Completed page 2/10 for topic api with stars upper limit 500000\n",
      "Completed page 3/10 for topic api with stars upper limit 500000\n",
      "Completed page 4/10 for topic api with stars upper limit 500000\n",
      "Reached repositories with stars less than 90. Moving to next topic.\n",
      "Finished processing topic: api\n",
      "Processing topic: python\n",
      "Total repositories found: 139131. Total pages: 10\n",
      "Completed page 1/10 for topic python with stars upper limit 500000\n",
      "Completed page 2/10 for topic python with stars upper limit 500000\n",
      "Completed page 3/10 for topic python with stars upper limit 500000\n",
      "Completed page 4/10 for topic python with stars upper limit 500000\n",
      "Completed page 5/10 for topic python with stars upper limit 500000\n",
      "Completed page 6/10 for topic python with stars upper limit 500000\n",
      "Completed page 7/10 for topic python with stars upper limit 500000\n",
      "Completed page 8/10 for topic python with stars upper limit 500000\n",
      "Completed page 9/10 for topic python with stars upper limit 500000\n",
      "Completed page 10/10 for topic python with stars upper limit 500000\n",
      "Adjusting stars upper limit to 2118 and continuing.\n",
      "Total repositories found: 138131. Total pages: 10\n",
      "Completed page 1/10 for topic python with stars upper limit 2118\n",
      "Completed page 2/10 for topic python with stars upper limit 2118\n",
      "Completed page 3/10 for topic python with stars upper limit 2118\n",
      "Completed page 4/10 for topic python with stars upper limit 2118\n",
      "Completed page 5/10 for topic python with stars upper limit 2118\n",
      "Completed page 6/10 for topic python with stars upper limit 2118\n",
      "Completed page 7/10 for topic python with stars upper limit 2118\n",
      "Completed page 8/10 for topic python with stars upper limit 2118\n",
      "Completed page 9/10 for topic python with stars upper limit 2118\n",
      "Completed page 10/10 for topic python with stars upper limit 2118\n",
      "Adjusting stars upper limit to 897 and continuing.\n",
      "Total repositories found: 137130. Total pages: 10\n",
      "Completed page 1/10 for topic python with stars upper limit 897\n",
      "Completed page 2/10 for topic python with stars upper limit 897\n",
      "Completed page 3/10 for topic python with stars upper limit 897\n",
      "Completed page 4/10 for topic python with stars upper limit 897\n",
      "Completed page 5/10 for topic python with stars upper limit 897\n",
      "Completed page 6/10 for topic python with stars upper limit 897\n",
      "Completed page 7/10 for topic python with stars upper limit 897\n",
      "Completed page 8/10 for topic python with stars upper limit 897\n",
      "Completed page 9/10 for topic python with stars upper limit 897\n",
      "Completed page 10/10 for topic python with stars upper limit 897\n",
      "Adjusting stars upper limit to 516 and continuing.\n",
      "Total repositories found: 136119. Total pages: 10\n",
      "Completed page 1/10 for topic python with stars upper limit 516\n",
      "Completed page 2/10 for topic python with stars upper limit 516\n",
      "Completed page 3/10 for topic python with stars upper limit 516\n",
      "Completed page 4/10 for topic python with stars upper limit 516\n",
      "Completed page 5/10 for topic python with stars upper limit 516\n",
      "Completed page 6/10 for topic python with stars upper limit 516\n",
      "Completed page 7/10 for topic python with stars upper limit 516\n",
      "Completed page 8/10 for topic python with stars upper limit 516\n",
      "Completed page 9/10 for topic python with stars upper limit 516\n",
      "Completed page 10/10 for topic python with stars upper limit 516\n",
      "Adjusting stars upper limit to 332 and continuing.\n",
      "Total repositories found: 135102. Total pages: 10\n",
      "Completed page 1/10 for topic python with stars upper limit 332\n",
      "Completed page 2/10 for topic python with stars upper limit 332\n",
      "Completed page 3/10 for topic python with stars upper limit 332\n",
      "Completed page 4/10 for topic python with stars upper limit 332\n",
      "Completed page 5/10 for topic python with stars upper limit 332\n",
      "Completed page 6/10 for topic python with stars upper limit 332\n",
      "Completed page 7/10 for topic python with stars upper limit 332\n",
      "Completed page 8/10 for topic python with stars upper limit 332\n",
      "Completed page 9/10 for topic python with stars upper limit 332\n",
      "Completed page 10/10 for topic python with stars upper limit 332\n",
      "Adjusting stars upper limit to 233 and continuing.\n",
      "Total repositories found: 134090. Total pages: 10\n",
      "Completed page 1/10 for topic python with stars upper limit 233\n",
      "Completed page 2/10 for topic python with stars upper limit 233\n",
      "Completed page 3/10 for topic python with stars upper limit 233\n",
      "Completed page 4/10 for topic python with stars upper limit 233\n",
      "Completed page 5/10 for topic python with stars upper limit 233\n",
      "Completed page 6/10 for topic python with stars upper limit 233\n",
      "Completed page 7/10 for topic python with stars upper limit 233\n",
      "Completed page 8/10 for topic python with stars upper limit 233\n",
      "Completed page 9/10 for topic python with stars upper limit 233\n",
      "Completed page 10/10 for topic python with stars upper limit 233\n",
      "Adjusting stars upper limit to 169 and continuing.\n",
      "Total repositories found: 133060. Total pages: 10\n",
      "Completed page 1/10 for topic python with stars upper limit 169\n",
      "Completed page 2/10 for topic python with stars upper limit 169\n",
      "Completed page 3/10 for topic python with stars upper limit 169\n",
      "Completed page 4/10 for topic python with stars upper limit 169\n",
      "Completed page 5/10 for topic python with stars upper limit 169\n",
      "Completed page 6/10 for topic python with stars upper limit 169\n",
      "Completed page 7/10 for topic python with stars upper limit 169\n",
      "Completed page 8/10 for topic python with stars upper limit 169\n",
      "Completed page 9/10 for topic python with stars upper limit 169\n",
      "Completed page 10/10 for topic python with stars upper limit 169\n",
      "Adjusting stars upper limit to 128 and continuing.\n",
      "Total repositories found: 132013. Total pages: 10\n",
      "Completed page 1/10 for topic python with stars upper limit 128\n",
      "Completed page 2/10 for topic python with stars upper limit 128\n",
      "Completed page 3/10 for topic python with stars upper limit 128\n",
      "Completed page 4/10 for topic python with stars upper limit 128\n",
      "Completed page 5/10 for topic python with stars upper limit 128\n",
      "Completed page 6/10 for topic python with stars upper limit 128\n",
      "Completed page 7/10 for topic python with stars upper limit 128\n",
      "Completed page 8/10 for topic python with stars upper limit 128\n",
      "Completed page 9/10 for topic python with stars upper limit 128\n",
      "Completed page 10/10 for topic python with stars upper limit 128\n",
      "Adjusting stars upper limit to 99 and continuing.\n",
      "Total repositories found: 130942. Total pages: 10\n",
      "Completed page 1/10 for topic python with stars upper limit 99\n",
      "Completed page 2/10 for topic python with stars upper limit 99\n",
      "Completed page 3/10 for topic python with stars upper limit 99\n",
      "Completed page 4/10 for topic python with stars upper limit 99\n",
      "Reached repositories with stars less than 90. Moving to next topic.\n",
      "Finished processing topic: python\n",
      "Processing topic: pytorch\n",
      "Total repositories found: 9272. Total pages: 10\n",
      "Completed page 1/10 for topic pytorch with stars upper limit 500000\n",
      "Completed page 2/10 for topic pytorch with stars upper limit 500000\n",
      "Completed page 3/10 for topic pytorch with stars upper limit 500000\n",
      "Completed page 4/10 for topic pytorch with stars upper limit 500000\n",
      "Completed page 5/10 for topic pytorch with stars upper limit 500000\n",
      "Completed page 6/10 for topic pytorch with stars upper limit 500000\n",
      "Completed page 7/10 for topic pytorch with stars upper limit 500000\n",
      "Completed page 8/10 for topic pytorch with stars upper limit 500000\n",
      "Completed page 9/10 for topic pytorch with stars upper limit 500000\n",
      "Completed page 10/10 for topic pytorch with stars upper limit 500000\n",
      "Adjusting stars upper limit to 364 and continuing.\n",
      "Total repositories found: 8271. Total pages: 10\n",
      "Completed page 1/10 for topic pytorch with stars upper limit 364\n",
      "Completed page 2/10 for topic pytorch with stars upper limit 364\n",
      "Completed page 3/10 for topic pytorch with stars upper limit 364\n",
      "Completed page 4/10 for topic pytorch with stars upper limit 364\n",
      "Completed page 5/10 for topic pytorch with stars upper limit 364\n",
      "Completed page 6/10 for topic pytorch with stars upper limit 364\n",
      "Completed page 7/10 for topic pytorch with stars upper limit 364\n",
      "Completed page 8/10 for topic pytorch with stars upper limit 364\n",
      "Completed page 9/10 for topic pytorch with stars upper limit 364\n",
      "Completed page 10/10 for topic pytorch with stars upper limit 364\n",
      "Adjusting stars upper limit to 96 and continuing.\n",
      "Total repositories found: 7261. Total pages: 10\n",
      "Reached repositories with stars less than 90. Moving to next topic.\n",
      "Finished processing topic: pytorch\n",
      "Processing topic: data-science\n",
      "Total repositories found: 4211. Total pages: 10\n",
      "Completed page 1/10 for topic data-science with stars upper limit 500000\n",
      "Completed page 2/10 for topic data-science with stars upper limit 500000\n",
      "Completed page 3/10 for topic data-science with stars upper limit 500000\n",
      "Completed page 4/10 for topic data-science with stars upper limit 500000\n",
      "Reached repositories with stars less than 90. Moving to next topic.\n",
      "Finished processing topic: data-science\n",
      "Processing topic: computer-vision\n",
      "Total repositories found: 5750. Total pages: 10\n",
      "Completed page 1/10 for topic computer-vision with stars upper limit 500000\n",
      "Completed page 2/10 for topic computer-vision with stars upper limit 500000\n",
      "Completed page 3/10 for topic computer-vision with stars upper limit 500000\n",
      "Completed page 4/10 for topic computer-vision with stars upper limit 500000\n",
      "Completed page 5/10 for topic computer-vision with stars upper limit 500000\n",
      "Completed page 6/10 for topic computer-vision with stars upper limit 500000\n",
      "Completed page 7/10 for topic computer-vision with stars upper limit 500000\n",
      "Reached repositories with stars less than 90. Moving to next topic.\n",
      "Finished processing topic: computer-vision\n",
      "Processing topic: tensorflow\n",
      "Total repositories found: 3668. Total pages: 10\n",
      "Completed page 1/10 for topic tensorflow with stars upper limit 500000\n",
      "Completed page 2/10 for topic tensorflow with stars upper limit 500000\n",
      "Completed page 3/10 for topic tensorflow with stars upper limit 500000\n",
      "Completed page 4/10 for topic tensorflow with stars upper limit 500000\n",
      "Completed page 5/10 for topic tensorflow with stars upper limit 500000\n",
      "Reached repositories with stars less than 90. Moving to next topic.\n",
      "Finished processing topic: tensorflow\n",
      "Processing topic: llm\n",
      "Total repositories found: 5769. Total pages: 10\n",
      "Completed page 1/10 for topic llm with stars upper limit 500000\n",
      "Completed page 2/10 for topic llm with stars upper limit 500000\n",
      "Completed page 3/10 for topic llm with stars upper limit 500000\n",
      "Completed page 4/10 for topic llm with stars upper limit 500000\n",
      "Completed page 5/10 for topic llm with stars upper limit 500000\n",
      "Completed page 6/10 for topic llm with stars upper limit 500000\n",
      "Completed page 7/10 for topic llm with stars upper limit 500000\n",
      "Completed page 8/10 for topic llm with stars upper limit 500000\n",
      "Reached repositories with stars less than 90. Moving to next topic.\n",
      "Finished processing topic: llm\n",
      "Processing topic: artificial-intelligence\n",
      "Total repositories found: 4171. Total pages: 10\n",
      "Completed page 1/10 for topic artificial-intelligence with stars upper limit 500000\n",
      "Completed page 2/10 for topic artificial-intelligence with stars upper limit 500000\n",
      "Completed page 3/10 for topic artificial-intelligence with stars upper limit 500000\n",
      "Completed page 4/10 for topic artificial-intelligence with stars upper limit 500000\n",
      "Completed page 5/10 for topic artificial-intelligence with stars upper limit 500000\n",
      "Reached repositories with stars less than 90. Moving to next topic.\n",
      "Finished processing topic: artificial-intelligence\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Headers for authentication\n",
    "headers = {}\n",
    "if ACCESS_TOKEN:\n",
    "    headers = {\"Authorization\": f\"token {ACCESS_TOKEN}\"}\n",
    "\n",
    "# Function to collect repository data\n",
    "def collect_repo_data():\n",
    "    repos_data = []\n",
    "    for topic in TOPICS:\n",
    "        print(f\"Processing topic: {topic}\")\n",
    "        stars_upper_limit = 500000  # Start with a very high star count\n",
    "        while True:\n",
    "            page = 1\n",
    "            first_page = True\n",
    "            total_pages = 1\n",
    "            last_star_count = None  # To keep track of the last repository's star count\n",
    "            while page <= total_pages:\n",
    "                query = f\"language:python stars:<{stars_upper_limit} fork:false topic:{topic} pushed:>=2023-01-01\"\n",
    "                params = {\n",
    "                    \"q\": query,\n",
    "                    \"sort\": \"stars\",\n",
    "                    \"order\": \"desc\",\n",
    "                    \"per_page\": PER_PAGE,\n",
    "                    \"page\": page\n",
    "                }\n",
    "\n",
    "                response = requests.get(f\"{GITHUB_API_URL}/search/repositories\", headers=headers, params=params)\n",
    "                if response.status_code != 200:\n",
    "                    print(f\"Failed to fetch repositories: {response.status_code}\")\n",
    "                    print(response.json())\n",
    "                    break\n",
    "\n",
    "                data = response.json()\n",
    "                if first_page:\n",
    "                    total_count = data.get('total_count', 0)\n",
    "                    total_pages = min((total_count + PER_PAGE - 1) // PER_PAGE, 10)  # API caps at 1000 results\n",
    "                    print(f\"Total repositories found: {total_count}. Total pages: {total_pages}\")\n",
    "                    first_page = False\n",
    "\n",
    "                items = data.get(\"items\", [])\n",
    "                if not items:\n",
    "                    print(f\"No repositories found on page {page}\")\n",
    "                    break\n",
    "\n",
    "                for repo in items:\n",
    "                    star_count = repo[\"stargazers_count\"]\n",
    "                    # Stop if the star count is below MIN_STAR\n",
    "                    if star_count < MIN_STAR:\n",
    "                        print(f\"Reached repositories with stars less than {MIN_STAR}. Moving to next topic.\")\n",
    "                        break\n",
    "                    repo_data = {\n",
    "                        \"repo_id\": repo[\"id\"],\n",
    "                        \"repo_name\": repo[\"name\"],\n",
    "                        \"full_name\": repo[\"full_name\"],\n",
    "                        \"owner_login\": repo[\"owner\"][\"login\"],\n",
    "                        \"repo_url\": repo[\"html_url\"],\n",
    "                        \"description\": repo[\"description\"],\n",
    "                        \"primary_language\": repo[\"language\"],\n",
    "                        \"topics\": repo.get(\"topics\", []),\n",
    "                        \"license\": repo[\"license\"][\"name\"] if repo[\"license\"] else None,\n",
    "                        \"created_at\": repo[\"created_at\"],\n",
    "                        \"updated_at\": repo[\"updated_at\"],\n",
    "                        \"pushed_at\": repo[\"pushed_at\"],\n",
    "                        \"size\": repo[\"size\"],\n",
    "                        \"stargazers_count\": star_count,\n",
    "                        \"watchers_count\": repo[\"watchers_count\"],\n",
    "                        \"forks_count\": repo[\"forks_count\"],\n",
    "                        \"open_issues_count\": repo[\"open_issues_count\"],\n",
    "                        \"default_branch\": repo[\"default_branch\"],\n",
    "                        \"score\": repo.get(\"score\"),\n",
    "                        \"is_fork\": repo[\"fork\"],\n",
    "                        \"visibility\": repo.get(\"visibility\", \"public\"),\n",
    "                        \"topic\": topic  # Include the topic\n",
    "                    }\n",
    "                    repos_data.append(repo_data)\n",
    "                    last_star_count = star_count\n",
    "                if star_count < MIN_STAR:\n",
    "                    break\n",
    "        \n",
    "\n",
    "                print(f\"Completed page {page}/{total_pages} for topic {topic} with stars upper limit {stars_upper_limit}\")\n",
    "                page += 1\n",
    "                time.sleep(1.5)  # Sleep to respect API rate limits\n",
    "                \n",
    "            if star_count < MIN_STAR:\n",
    "                break\n",
    "\n",
    "            # If total_count is less than 1000, we've retrieved all repositories for this stars_upper_limit\n",
    "            if total_count < 1000:\n",
    "                print(f\"All repositories fetched for stars less than {stars_upper_limit}.\")\n",
    "                break\n",
    "            elif last_star_count is not None:\n",
    "                # Update the stars_upper_limit to be less than the last star count\n",
    "                stars_upper_limit = last_star_count - 1\n",
    "                print(f\"Adjusting stars upper limit to {stars_upper_limit} and continuing.\")\n",
    "            else:\n",
    "                # No more repositories to fetch\n",
    "                break\n",
    "        print(f\"Finished processing topic: {topic}\")\n",
    "\n",
    "    return repos_data\n",
    "\n",
    "\n",
    "repos_data = collect_repo_data()\n",
    "\n",
    "# Save repos_data to CSV\n",
    "repos_df = pd.DataFrame(repos_data)\n",
    "repos_df = repos_df.drop_duplicates(subset=[\"full_name\"])\n",
    "repos_df.to_csv(\"repositories_.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "headers = {}\n",
    "if ACCESS_TOKEN:\n",
    "    headers = {\"Authorization\": f\"token {ACCESS_TOKEN}\"}\n",
    "\n",
    "# Function to fetch READMEs for a list of repositories\n",
    "def fetch_readmes(repo_full_names):\n",
    "    readme_errors = []\n",
    "    if not os.path.exists(\"readmes\"):\n",
    "        os.makedirs(\"readmes\")\n",
    "\n",
    "    for repo_full_name in tqdm(repo_full_names):\n",
    "\n",
    "        #skip if readme already exists\n",
    "        if os.path.exists(f\"readmes/{repo_full_name.replace('/', '_')}.md\"):\n",
    "            continue\n",
    "\n",
    "\n",
    "        readme_url = f\"{GITHUB_API_URL}/repos/{repo_full_name}/readme\"\n",
    "\n",
    "        # Create a copy of headers and add 'Accept' header\n",
    "        readme_headers = headers.copy()\n",
    "        readme_headers['Accept'] = 'application/vnd.github.v3.raw'\n",
    "\n",
    "        readme_resp = requests.get(readme_url, headers=readme_headers)\n",
    "\n",
    "        if readme_resp.status_code == 200:\n",
    "            # Save README to a file named after the repo full name\n",
    "            # Replace slashes in the full name to make it a valid filename\n",
    "            safe_name = repo_full_name.replace(\"/\", \"_\")\n",
    "            with open(f\"readmes/{safe_name}.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(readme_resp.text)\n",
    "        else:\n",
    "            readme_errors.append((repo_full_name, readme_resp.status_code))\n",
    "            continue  # Skip repositories without README\n",
    "\n",
    "        time.sleep(0.2)  # Sleep to respect API rate limits\n",
    "\n",
    "    return readme_errors\n",
    "\n",
    "repos_df = pd.read_csv(\"repositories.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12751/12751 [45:35<00:00,  4.66it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('sksalahuddin2828/Pandas_Numpy_Matplotlib_Plotly', 404),\n",
       " ('oliveirabruno01/babyagi-asi', 404),\n",
       " ('engineer-man/youtube', 404),\n",
       " ('BotoX/xiaomi-m365-firmware-patcher', 404),\n",
       " ('Artfunkel/BlenderSourceTools', 404),\n",
       " ('lilydjwg/winterpy', 404),\n",
       " ('K-G-PRAJWAL/Python-Projects', 404),\n",
       " ('fmartinou/tydom2mqtt', 404),\n",
       " ('JonasSchult/Mask3D', 403),\n",
       " ('emidan19/deep-tempest', 403),\n",
       " ('xlang-ai/UnifiedSKG', 403),\n",
       " ('snap-stanford/deepsnap', 403),\n",
       " ('wuji3/visiondk', 403),\n",
       " ('AmazingDD/daisyRec', 403),\n",
       " ('kuanghuei/SCAN', 403),\n",
       " ('pyg-team/pytorch-frame', 403),\n",
       " ('nomic-ai/contrastors', 403),\n",
       " ('tatp22/multidim-positional-encoding', 403),\n",
       " ('metaopt/torchopt', 403),\n",
       " ('kjsman/stable-diffusion-pytorch', 403),\n",
       " ('hkchengrex/STCN', 403),\n",
       " ('voidful/TextRL', 403),\n",
       " ('IntelLabs/bayesian-torch', 403),\n",
       " ('clcarwin/convert_torch_to_pytorch', 403),\n",
       " ('akanimax/pro_gan_pytorch', 403),\n",
       " ('v-iashin/video_features', 403),\n",
       " ('610265158/Peppa_Pig_Face_Landmark', 403),\n",
       " ('bradyz/cross_view_transformers', 403),\n",
       " ('jiwoon-ahn/irn', 403),\n",
       " ('texttron/tevatron', 403),\n",
       " ('hassony2/kinetics_i3d_pytorch', 403),\n",
       " ('Azure/MS-AMP', 403),\n",
       " ('VITA-Group/FasterSeg', 403),\n",
       " ('taishan1994/pytorch_bert_bilstm_crf_ner', 403),\n",
       " ('ldeecke/gmm-torch', 403),\n",
       " ('naver/roma', 403),\n",
       " ('DagnyT/hardnet', 403),\n",
       " ('swz30/CycleISP', 403),\n",
       " ('znxlwm/pytorch-MNIST-CelebA-GAN-DCGAN', 403),\n",
       " ('jasoncao11/nlp-notebook', 403),\n",
       " ('microsoft/StyleSwin', 403),\n",
       " ('w86763777/pytorch-ddpm', 403),\n",
       " ('medipixel/rl_algorithms', 403),\n",
       " ('cardwing/Codes-for-PVKD', 403),\n",
       " ('zhou13/lcnn', 403),\n",
       " ('RUCAIBox/CRSLab', 403),\n",
       " ('WAMAWAMA/WAMA_Modules', 403),\n",
       " ('jaketae/storyteller', 403),\n",
       " ('hazdzz/STGCN', 403),\n",
       " ('thuml/depyf', 403),\n",
       " ('trackmania-rl/tmrl', 403),\n",
       " ('ma-xu/pointMLP-pytorch', 403),\n",
       " ('Media-Smart/vedadet', 403),\n",
       " ('Harry24k/bayesian-neural-network-pytorch', 403),\n",
       " ('NTMC-Community/MatchZoo-py', 403),\n",
       " ('plemeri/InSPyReNet', 403),\n",
       " ('DIYer22/boxx', 403),\n",
       " ('giddyyupp/ganilla', 403),\n",
       " ('p0p4k/vits2_pytorch', 403),\n",
       " ('layumi/University1652-Baseline', 403),\n",
       " ('cvqluu/Angular-Penalty-Softmax-Losses-Pytorch', 403),\n",
       " ('mit-han-lab/mcunet', 403),\n",
       " ('vikasverma1077/manifold_mixup', 403),\n",
       " ('mks0601/3DMPPE_ROOTNET_RELEASE', 403),\n",
       " ('cuiziteng/Illumination-Adaptive-Transformer', 403),\n",
       " ('crowsonkb/style-transfer-pytorch', 403),\n",
       " ('fkodom/fft-conv-pytorch', 403),\n",
       " ('THUDM/GraphMAE', 403),\n",
       " ('davidefiocco/streamlit-fastapi-model-serving', 403),\n",
       " ('xming521/CTAI', 403),\n",
       " ('EagleW/PaperRobot', 403),\n",
       " ('vietnh1009/Tetris-deep-Q-learning-pytorch', 403),\n",
       " ('kevinzakka/recurrent-visual-attention', 403),\n",
       " ('hkchengrex/MiVOS', 403),\n",
       " ('gangweiX/ACVNet', 403),\n",
       " ('salesforce/warp-drive', 403),\n",
       " ('VITA-Group/AutoGAN', 403),\n",
       " ('Ha0Tang/SelectionGAN', 403),\n",
       " ('UM-ARM-Lab/pytorch_mppi', 403),\n",
       " ('threelittlemonkeys/lstm-crf-pytorch', 403),\n",
       " ('EdisonLeeeee/GraphGallery', 403),\n",
       " ('mir-aidj/all-in-one', 403),\n",
       " ('bshall/knn-vc', 403),\n",
       " ('phamquiluan/ResidualMaskingNetwork', 403),\n",
       " ('layumi/AICIty-reID-2020', 403),\n",
       " ('hemingkx/ChineseNMT', 403),\n",
       " ('JeffersonQin/YuzuMarker.FontDetection', 403),\n",
       " ('skhadem/3D-BoundingBox', 403),\n",
       " ('Stanford-TML/EDGE', 403),\n",
       " ('iBelieveCJM/Tricks-of-Semi-supervisedDeepLeanring-Pytorch', 403),\n",
       " ('LSH9832/edgeyolo', 403),\n",
       " ('UM-ARM-Lab/pytorch_kinematics', 403),\n",
       " ('jalola/improved-wgan-pytorch', 403),\n",
       " ('lemonhu/NER-BERT-pytorch', 403),\n",
       " ('santi-pdp/pase', 403),\n",
       " ('kmeng01/memit', 403),\n",
       " ('dougbrion/pytorch-classification-uncertainty', 403),\n",
       " ('Haochen-Wang409/U2PL', 403),\n",
       " ('Jacen789/relation-extraction', 403),\n",
       " ('JusperLee/Conv-TasNet', 403),\n",
       " ('microsoft/UniSpeech', 403),\n",
       " ('songquanpeng/pytorch-template', 403),\n",
       " ('wgcban/ChangeFormer', 403),\n",
       " ('kenziyuliu/MS-G3D', 403),\n",
       " ('shobrook/sequitur', 403),\n",
       " ('DPS2022/diffusion-posterior-sampling', 403),\n",
       " ('DerryHub/BEVFormer_tensorrt', 403),\n",
       " ('abhiskk/fast-neural-style', 403),\n",
       " ('NM512/dreamerv3-torch', 403),\n",
       " ('timy90022/One-Shot-Object-Detection', 403),\n",
       " ('Lornatang/SRGAN-PyTorch', 403),\n",
       " ('NVIDIA/framework-reproducibility', 403),\n",
       " ('kyegomez/zeta', 403),\n",
       " ('NasirKhalid24/CLIP-Mesh', 403),\n",
       " ('GAP-LAB-CUHK-SZ/Total3DUnderstanding', 403),\n",
       " ('shinya7y/UniverseNet', 403),\n",
       " ('datawhalechina/torch-rechub', 403),\n",
       " ('zgcr/SimpleAICV_pytorch_training_examples', 403),\n",
       " ('ViTAE-Transformer/Remote-Sensing-RVSA', 403),\n",
       " ('yeyupiaoling/AudioClassification-Pytorch', 403),\n",
       " ('JusperLee/Dual-Path-RNN-Pytorch', 403),\n",
       " ('hysts/anime-face-detector', 403),\n",
       " ('PistonY/torch-toolbox', 403),\n",
       " ('swz30/MIRNetv2', 403),\n",
       " ('modelscope/AdaSeq', 403),\n",
       " ('Continvvm/continuum', 403),\n",
       " ('ClementPinard/Pytorch-Correlation-extension', 403),\n",
       " ('gengshan-y/high-res-stereo', 403),\n",
       " ('Zhen-Dong/HAWQ', 403),\n",
       " ('jiaxi-jiang/FBCNN', 403),\n",
       " ('sacmehta/EdgeNets', 403),\n",
       " ('vaseline555/Federated-Learning-in-PyTorch', 403),\n",
       " ('OpenMOSS/CoLLiE', 403),\n",
       " ('francois-rozet/piqa', 403),\n",
       " ('maxrmorrison/torchcrepe', 403),\n",
       " ('NVIDIA-Merlin/dataloader', 403),\n",
       " ('fadel/pytorch_ema', 403),\n",
       " ('pochih/FCN-pytorch', 403),\n",
       " ('mees/calvin', 403),\n",
       " ('yanx27/2DPASS', 403),\n",
       " ('assassint2017/MICCAI-LITS2017', 403),\n",
       " ('yl4579/StyleTTS', 403),\n",
       " ('Seeed-Studio/ModelAssistant', 403),\n",
       " ('kamalkraj/BERT-SQuAD', 403),\n",
       " ('yatengLG/SSD-Pytorch', 403),\n",
       " ('nanoporetech/bonito', 403),\n",
       " ('Rubics-Xuan/TransBTS', 403),\n",
       " ('ternaus/retinaface', 403),\n",
       " ('Tony-Y/pytorch_warmup', 403),\n",
       " ('Skylark0924/Machine-Learning-is-ALL-You-Need', 403),\n",
       " ('sarathknv/adversarial-examples-pytorch', 403),\n",
       " ('arthurdouillard/incremental_learning.pytorch', 403),\n",
       " ('Haiyang-W/DSVT', 403),\n",
       " ('Shivanandroy/simpleT5', 403),\n",
       " ('vadimkantorov/caffemodel2pytorch', 403),\n",
       " ('layumi/Seg-Uncertainty', 403),\n",
       " ('McGregorWwww/UCTransNet', 403),\n",
       " ('linwhitehat/ET-BERT', 403),\n",
       " ('HugAILab/HugNLP', 403),\n",
       " ('threedle/GeoCode', 403),\n",
       " ('BobaZooba/xllm', 403),\n",
       " ('megvii-research/MOTRv2', 403),\n",
       " ('intelligent-machine-learning/glake', 403),\n",
       " ('JohnGiorgi/DeCLUTR', 403),\n",
       " ('alibaba/lightweight-neural-architecture-search', 403),\n",
       " ('santi-pdp/segan_pytorch', 403),\n",
       " ('dptech-corp/Uni-Fold', 403),\n",
       " ('khanhha/crack_segmentation', 403),\n",
       " ('csuhan/s2anet', 403),\n",
       " ('vietnh1009/Yolo-v2-pytorch', 403),\n",
       " ('stepankonev/waymo-motion-prediction-challenge-2022-multipath-plus-plus',\n",
       "  403),\n",
       " ('itailang/SampleNet', 403),\n",
       " ('binli123/dsmil-wsi', 403),\n",
       " ('yanwii/ChinsesNER-pytorch', 403),\n",
       " ('Owen-Liuyuxuan/visualDet3D', 403),\n",
       " ('wuyifan18/DeepLog', 403),\n",
       " ('PacktPublishing/Hands-On-Intelligent-Agents-with-OpenAI-Gym', 403),\n",
       " ('text2cinemagraph/text2cinemagraph', 403),\n",
       " ('AI4Finance-Foundation/FinRL_Podracer', 403),\n",
       " ('taokong/FoveaBox', 403),\n",
       " ('HikariTJU/LD', 403),\n",
       " ('jeya-maria-jose/KiU-Net-pytorch', 403),\n",
       " ('NeuromorphicProcessorProject/snn_toolbox', 403),\n",
       " ('feifeibear/long-context-attention', 403),\n",
       " ('QUVA-Lab/escnn', 403),\n",
       " ('HaozheLiu-ST/T-GATE', 403),\n",
       " ('kakaoenterprise/JORLDY', 403),\n",
       " ('cheerss/CrossFormer', 403),\n",
       " ('Jungjee/RawNet', 403),\n",
       " ('luyug/GradCache', 403),\n",
       " ('chineseocr/trocr-chinese', 403),\n",
       " ('Junjue-Wang/LoveDA', 403),\n",
       " ('as-ideas/DeepPhonemizer', 403),\n",
       " ('Xiaoccer/MobileFaceNet_Pytorch', 403),\n",
       " ('Pointcept/PointTransformerV2', 403),\n",
       " ('sithu31296/PyTorch-ONNX-TFLite', 403),\n",
       " ('jaywonchung/BERT4Rec-VAE-Pytorch', 403),\n",
       " ('ServerlessLLM/ServerlessLLM', 403),\n",
       " ('astra-vision/SceneRF', 403),\n",
       " ('universome/stylegan-v', 403),\n",
       " ('hysts/pytorch_mpiigaze', 403),\n",
       " ('minar09/cp-vton-plus', 403),\n",
       " ('pmixer/SASRec.pytorch', 403),\n",
       " ('THU-KEG/OmniEvent', 403),\n",
       " ('yangyuke001/FIIQA-PyTorch', 403),\n",
       " ('monologg/R-BERT', 403),\n",
       " ('JackHCC/Chinese-Text-Classification-PyTorch', 403),\n",
       " ('va1shn9v/PromptIR', 403),\n",
       " ('maum-ai/hififace', 403),\n",
       " ('Fangyh09/pytorch-receptive-field', 403),\n",
       " ('wenzhu23333/Differential-Privacy-Based-Federated-Learning', 403),\n",
       " ('HowieMa/DeepSORT_YOLOv5_Pytorch', 403),\n",
       " ('proroklab/VectorizedMultiAgentSimulator', 403),\n",
       " ('Beomi/InfiniTransformer', 403),\n",
       " ('sahilg06/EmoGen', 403),\n",
       " ('filaPro/oneformer3d', 403),\n",
       " ('vballoli/nfnets-pytorch', 403),\n",
       " ('tsujuifu/pytorch_mgie', 403),\n",
       " ('iMoonLab/MeshNet', 403),\n",
       " ('SeuTao/TGS-Salt-Identification', 403),\n",
       " ('FlagOpen/FlagGems', 403),\n",
       " ('AntixK/PyTorch-Model-Compare', 403),\n",
       " ('inisis/brocolli', 403),\n",
       " ('jankrepl/mildlyoverfitted', 403),\n",
       " ('Ahmednull/L2CS-Net', 403),\n",
       " ('microsoft/CoCosNet-v2', 403),\n",
       " ('apple/ml-gmpi', 403),\n",
       " ('ucuapps/OpenGlue', 403),\n",
       " ('dmmiller612/sparktorch', 403),\n",
       " ('ML4ITS/mtad-gat-pytorch', 403),\n",
       " ('ixaxaar/pytorch-dnc', 403),\n",
       " ('mjhydri/BeatNet', 403),\n",
       " ('yongzhuo/Pytorch-NLU', 403),\n",
       " ('budzianowski/PyTorch-Beam-Search-Decoding', 403),\n",
       " ('bethgelab/model-vs-human', 403),\n",
       " ('golsun/DialogRPT', 403),\n",
       " ('wzhouxiff/RestoreFormer', 403),\n",
       " ('amirbar/DETReg', 403),\n",
       " ('likyoo/change_detection.pytorch', 403),\n",
       " ('taishan1994/pytorch_triple_extraction', 403),\n",
       " ('luping-liu/PNDM', 403),\n",
       " ('bshall/hubert', 403),\n",
       " ('Xiuyu-Li/q-diffusion', 403),\n",
       " ('gmongaras/Diffusion_models_from_scratch', 403),\n",
       " ('bshall/ZeroSpeech', 403),\n",
       " ('gitabcworld/MatchingNetworks', 403),\n",
       " ('holmescao/TOPICTrack', 403),\n",
       " ('asahi417/lm-question-generation', 403),\n",
       " ('mxl1990/tsne-pytorch', 403),\n",
       " ('myungsub/CAIN', 403),\n",
       " ('lumina37/rotate-captcha-crack', 403),\n",
       " ('AngeLouCN/DC-UNet', 403),\n",
       " ('richarddwang/electra_pytorch', 403),\n",
       " ('WangFeng18/3d-gaussian-splatting', 403),\n",
       " ('Eclectic-Sheep/sheeprl', 403),\n",
       " ('0ssamaak0/DLTA-AI', 403),\n",
       " ('Srameo/LED', 403),\n",
       " ('raoyongming/HorNet', 403),\n",
       " ('rfeinman/pytorch-minimize', 403),\n",
       " ('neuralmagic/sparsify', 403),\n",
       " ('rrmina/fast-neural-style-pytorch', 403),\n",
       " ('LucasAlegre/morl-baselines', 403),\n",
       " ('frgfm/Holocron', 403),\n",
       " ('nimarb/pytorch_influence_functions', 403),\n",
       " ('yxlu-0102/MP-SENet', 403),\n",
       " ('jw9730/tokengt', 403),\n",
       " ('DocF/multispectral-object-detection', 403),\n",
       " ('spfrommer/torchexplorer', 403),\n",
       " ('VITA-Group/NeuralLift-360', 403),\n",
       " ('chenyaofo/pytorch-cifar-models', 403),\n",
       " ('hlwang1124/SNE-RoadSeg', 403),\n",
       " ('raywzy/ICT', 403),\n",
       " ('theEricMa/OTAvatar', 403),\n",
       " ('SJTMusicTeam/Muskits', 403),\n",
       " ('hysts/pytorch_mpiigaze_demo', 403),\n",
       " ('zc-alexfan/arctic', 403),\n",
       " ('InternLM/InternEvo', 403),\n",
       " ('megvii-research/FQ-ViT', 403),\n",
       " ('twni2016/pomdp-baselines', 403),\n",
       " ('rwightman/posenet-pytorch', 403),\n",
       " ('hzxie/GRNet', 403),\n",
       " ('ENSTA-U2IS-AI/torch-uncertainty', 403),\n",
       " ('HUANGLIZI/LViT', 403),\n",
       " ('sajjjadayobi/FaceLib', 403),\n",
       " ('dingkeyan93/IQA-optimization', 403),\n",
       " ('mmaaz60/mvits_for_class_agnostic_od', 403),\n",
       " ('zhejz/carla-roach', 403),\n",
       " ('gmberton/CosPlace', 403),\n",
       " ('bamos/block', 403),\n",
       " ('SensorsINI/v2e', 403),\n",
       " ('cyoon1729/RLcycle', 403),\n",
       " ('qitianwu/DIFFormer', 403),\n",
       " ('v0lta/PyTorch-Wavelet-Toolbox', 403),\n",
       " ('UCSC-VLAA/CLIPA', 403),\n",
       " ('idreesshaikh/Autonomous-Driving-in-Carla-using-Deep-Reinforcement-Learning',\n",
       "  403),\n",
       " ('GAP-LAB-CUHK-SZ/REC-MV', 403),\n",
       " ('Luodian/Generalizable-Mixture-of-Experts', 403),\n",
       " ('AssemblyAI-Community/MinImagen', 403),\n",
       " ('suyukun666/UFO', 403),\n",
       " ('wonjongg/StyleCariGAN', 403),\n",
       " ('tianyic/only_train_once_personal_footprint', 403),\n",
       " ('quiver-team/torch-quiver', 403),\n",
       " ('affjljoo3581/GPT2', 403),\n",
       " ('LambdaLabsML/distributed-training-guide', 403),\n",
       " ('TZYSJTU/Sketch-Generation-with-Drawing-Process-Guided-by-Vector-Flow-and-Grayscale',\n",
       "  403),\n",
       " ('sunzeyeah/RLHF', 403),\n",
       " ('Lin-Yijie/Graph-Matching-Networks', 403),\n",
       " ('thuanz123/enhancing-transformers', 403),\n",
       " ('zibojia/COCOCO', 403),\n",
       " ('otaheri/MANO', 403),\n",
       " ('woshidandan/TANet-image-aesthetics-and-quality-assessment', 403),\n",
       " ('loeweX/Greedy_InfoMax', 403),\n",
       " ('SamsungLabs/imvoxelnet', 403),\n",
       " ('AngeLouCN/CFPNet-Medicine', 403),\n",
       " ('guochengqian/TENet', 403),\n",
       " ('dingo-actual/infini-transformer', 403),\n",
       " ('pmj110119/YOLOX_deepsort_tracker', 403),\n",
       " ('yihaosun1124/OfflineRL-Kit', 403),\n",
       " ('sunny2109/SAFMN', 403),\n",
       " ('IDEA-Research/HumanSD', 403),\n",
       " ('showlab/all-in-one', 403),\n",
       " ('maum-ai/nuwave2', 403),\n",
       " ('jkulhanek/tetra-nerf', 403),\n",
       " ('numenta/nupic.torch', 403),\n",
       " ('ain-soph/trojanzoo', 403),\n",
       " ('delijati/pytorch-siamese', 403),\n",
       " ('leeesangwon/PyTorch-Image-Retrieval', 403),\n",
       " ('BIGBALLON/distribuuuu', 403),\n",
       " ('ltkong218/IFRNet', 403),\n",
       " ('TorchSpatiotemporal/tsl', 403),\n",
       " ('yistLin/dvector', 403),\n",
       " ('krishnap25/mauve', 403),\n",
       " ('lannguyen0910/food-recognition', 403),\n",
       " ('rezaakb/pinns-torch', 403),\n",
       " ('feipanir/IntraDA', 403),\n",
       " ('tsujuifu/pytorch_graph-rel', 403),\n",
       " ('jayleicn/moment_detr', 403),\n",
       " ('NikolaZubic/2dimageto3dmodel', 403),\n",
       " ('yhygao/CBIM-Medical-Image-Segmentation', 403),\n",
       " ('SamsungLabs/image_harmonization', 403),\n",
       " ('songweige/TATS', 403),\n",
       " ('durandtibo/wildcat.pytorch', 403),\n",
       " ('MILVLG/prophet', 403),\n",
       " ('yiqun-wang/PET-NeuS', 403),\n",
       " ('gitabtion/BertBasedCorrectionModels', 403),\n",
       " ('layumi/person-reid-3d', 403),\n",
       " ('salesforce/ETSformer', 403),\n",
       " ('baaihealth/OpenComplex', 403),\n",
       " ('sgrvinod/a-PyTorch-Tutorial-to-Transformers', 403),\n",
       " ('neggles/animatediff-cli', 403),\n",
       " ('sebastian-hofstaetter/matchmaker', 403),\n",
       " ('Ricardokevins/Kevinpro-NLP-demo', 403),\n",
       " ('bighuang624/DSANet', 403),\n",
       " ('misads/easy_detection', 403),\n",
       " ('ltkong218/FastFlowNet', 403),\n",
       " ('huggingface/optimum-benchmark', 403),\n",
       " ('cmhungsteve/TA3N', 403),\n",
       " ('vasistalodagala/whisper-finetune', 403),\n",
       " ('dgriff777/a3c_continuous', 403),\n",
       " ('Khrylx/AgentFormer', 403),\n",
       " ('zhangbaijin/SpA-Former-shadow-removal', 403),\n",
       " ('remotebiosensing/rppg', 403),\n",
       " ('Nota-NetsPresso/BK-SDM', 403),\n",
       " ('nianticlabs/map-free-reloc', 403),\n",
       " ('hkproj/pytorch-llama', 403),\n",
       " ('Ascend/pytorch', 403),\n",
       " ('mertyg/vision-language-models-are-bows', 403),\n",
       " ('wholebody3d/wholebody3d', 403),\n",
       " ('iflytek/MiniRBT', 403),\n",
       " ('elvisyjlin/AttGAN-PyTorch', 403),\n",
       " ('ziplab/LITv2', 403),\n",
       " ('lliuz/ARFlow', 403),\n",
       " ('atomicoo/FCH-TTS', 403),\n",
       " ('yuyangw/MolCLR', 403),\n",
       " ('QitaoZhao/PoseFormerV2', 403),\n",
       " ('kkirchheim/pytorch-ood', 403),\n",
       " ('ShengranHu/Thought-Cloning', 403),\n",
       " ('Picsart-AI-Research/SeMask-Segmentation', 403),\n",
       " ('nkolkin13/NeuralNeighborStyleTransfer', 403),\n",
       " ('cloneofsimo/consistency_models', 403),\n",
       " ('megvii-research/RevCol', 403),\n",
       " ('NYUMedML/GNN_for_EHR', 403),\n",
       " ('GitYCC/crnn-pytorch', 403),\n",
       " ('wjn1996/HugNLP', 403),\n",
       " ('xrenaa/Music-Dance-Video-Synthesis', 403),\n",
       " ('Executedone/Chinese-FastSpeech2', 403),\n",
       " ('hyperdimensional-computing/torchhd', 403),\n",
       " ('hujinsen/pytorch-StarGAN-VC', 403),\n",
       " ('microsoft/sarathi-serve', 403),\n",
       " ('jidasheng/bi-lstm-crf', 403),\n",
       " ('avBuffer/UNet3plus_pth', 403),\n",
       " ('jolibrain/joliGEN', 403),\n",
       " ('himashi92/VT-UNet', 403),\n",
       " ('ruhyadi/YOLO3D', 403),\n",
       " ('THU-MIG/torch-model-compression', 403),\n",
       " ('INVOKERer/DeepRFT', 403),\n",
       " ('mzjb/DeepH-pack', 403),\n",
       " ('openclimatefix/metnet', 403),\n",
       " ('GalaxyLearning/GFL', 403),\n",
       " ('j-min/Adversarial_Video_Summary', 403),\n",
       " ('coolzhao/Geo-SAM', 403),\n",
       " ('dingkeyan93/Intrinsic-Image-Popularity', 403),\n",
       " ('rendchevi/nix-tts', 403),\n",
       " ('dvlab-research/Parametric-Contrastive-Learning', 403),\n",
       " ('JunyaoHu/common_metrics_on_video_quality', 403),\n",
       " ('gmayday1997/SceneChangeDet', 403),\n",
       " ('HasnainRaz/Fast-AgingGAN', 403),\n",
       " ('NKI-AI/direct', 403),\n",
       " ('Cyanogenoid/pytorch-vqa', 403),\n",
       " ('Koopman-Laboratory/KoopmanLab', 403),\n",
       " ('Mayukhdeb/torch-dreams', 403),\n",
       " ('fschmid56/EfficientAT', 403),\n",
       " ('daveredrum/ScanRefer', 403),\n",
       " ('kozistr/pytorch_optimizer', 403),\n",
       " ('rlleshi/phar', 403),\n",
       " ('luopeixiang/textclf', 403),\n",
       " ('vinthony/deep-blind-watermark-removal', 403),\n",
       " ('AI-Hypercomputer/JetStream', 403),\n",
       " ('Runinho/pytorch-cutpaste', 403),\n",
       " ('GewelsJI/SINet-V2', 403),\n",
       " ('Royalvice/DocDiff', 403),\n",
       " ('Spico197/DocEE', 403),\n",
       " ('martenlienen/torchode', 403),\n",
       " ('ControlNet/MARLIN', 403),\n",
       " ('Audio-WestlakeU/NBSS', 403),\n",
       " ('cecret3350/DEA-Net', 403),\n",
       " ('nayeemrizve/ups', 403),\n",
       " ('yoyolicoris/pytorch-NMF', 403),\n",
       " ('SamsungLabs/fcaf3d', 403),\n",
       " ('CyberAgentAILab/layout-dm', 403),\n",
       " ('showlab/EgoVLP', 403),\n",
       " ('j-marple-dev/model_compression', 403),\n",
       " ('tobran/GALIP', 403),\n",
       " ('codeslake/IFAN', 403),\n",
       " ('drprojects/DeepViewAgg', 403),\n",
       " ('MuhammadMoinFaisal/Automatic_Number_Plate_Detection_Recognition_YOLOv8',\n",
       "  403),\n",
       " ('Ha0Tang/XingGAN', 403),\n",
       " ('alibaba-mmai-research/TAdaConv', 403),\n",
       " ('yannvgn/laserembeddings', 403),\n",
       " ('mattragoza/LiGAN', 403),\n",
       " ('syguan96/DynaBOA', 403),\n",
       " ('opendilab/DI-hpc', 403),\n",
       " ('amaralibey/MixVPR', 403),\n",
       " ('ZhangYuanhan-AI/NOAH', 403),\n",
       " ('pmeier/light-the-torch', 403),\n",
       " ('hugochan/IDGL', 403),\n",
       " ('megvii-research/DCLS-SR', 403),\n",
       " ('scaomath/galerkin-transformer', 403),\n",
       " ('zzh-tech/BiT', 403),\n",
       " ('vithursant/MagnetLoss-PyTorch', 403),\n",
       " ('openclimatefix/skillful_nowcasting', 403),\n",
       " ('huyanxin/phasen', 403),\n",
       " ('SeokjuLee/Insta-DM', 403),\n",
       " ('BUPT-GAMMA/GammaGL', 403),\n",
       " ('tomchang25/whisper-auto-transcribe', 403),\n",
       " ('nianticlabs/footprints', 403),\n",
       " ('ashutosh1919/explainable-cnn', 403),\n",
       " ('yueliu1999/DCRN', 403),\n",
       " ('eth-sri/diffai', 403),\n",
       " ('matteo-ronchetti/torch-radon', 403),\n",
       " ('yzd-v/cls_KD', 403),\n",
       " ('SunnyGJing/t5-pegasus-chinese', 403),\n",
       " ('bcmi/SLBR-Visible-Watermark-Removal', 403),\n",
       " ('hughplay/DFNet', 403),\n",
       " ('p0p4k/pflowtts_pytorch', 403),\n",
       " ('jiachens/ModelNet40-C', 403),\n",
       " ('mats-robotics/yolov5_ros', 403),\n",
       " ('uncbiag/SimpleClick', 403),\n",
       " ('recursionpharma/gflownet', 403),\n",
       " ('iflytek/cino', 403),\n",
       " ('mmuckley/torchkbnufft', 403),\n",
       " ('IC3Net/IC3Net', 403),\n",
       " ('maum-ai/cotatron', 403),\n",
       " ('sxhxliang/detectron2_backbone', 403),\n",
       " ('RQ-Wu/RIDCP_dehazing', 403),\n",
       " ('fxmeng/RMNet', 403),\n",
       " ('1ytic/warp-rnnt', 403),\n",
       " ('SamsungLabs/iterdet', 403),\n",
       " ('wmcnally/golfdb', 403),\n",
       " ('funcwj/conv-tasnet', 403),\n",
       " ('foolwood/DCFNet_pytorch', 403),\n",
       " ('gorodnitskiy/yet-another-lightning-hydra-template', 403),\n",
       " ('aredden/flux-fp8-api', 403),\n",
       " ('Deepest-Project/MelNet', 403),\n",
       " ('RoyalVane/MMAN', 403),\n",
       " ('jackaduma/Vicuna-LoRA-RLHF-PyTorch', 403),\n",
       " ('tfjgeorge/nngeometry', 403),\n",
       " ('GAP-LAB-CUHK-SZ/RfDNet', 403),\n",
       " ('chuhaojin/Text2Poster-ICASSP-22', 403),\n",
       " ('xashru/punctuation-restoration', 403),\n",
       " ('Intelligent-Driving-Laboratory/GOPS', 403),\n",
       " ('Kchu/DeepRL_PyTorch', 403),\n",
       " ('a-r-j/ProteinWorkshop', 403),\n",
       " ('stanleylsx/llms_tool', 403),\n",
       " ('JinyuanLiu-CV/TarDAL', 403),\n",
       " ('monologg/KoBigBird', 403),\n",
       " ('ymcui/LERT', 403),\n",
       " ('keonlee9420/DailyTalk', 403),\n",
       " ('jhultman/vision3d', 403),\n",
       " ('OctoberChang/MMD-GAN', 403),\n",
       " ('emadeldeen24/AttnSleep', 403),\n",
       " ('aws/sagemaker-pytorch-training-toolkit', 403),\n",
       " ('sony/bigvsan', 403),\n",
       " ('openclimatefix/graph_weather', 403),\n",
       " ('junhsss/consistency-models', 403),\n",
       " ('monniert/differentiable-blocksworld', 403),\n",
       " ('AlanLi1997/slim-neck-by-gsconv', 403),\n",
       " ('learnables/cherry', 403),\n",
       " ('tugstugi/pytorch-speech-commands', 403),\n",
       " ('silviutroscot/CodeSLAM', 403),\n",
       " ('Karel911/TRACER', 403),\n",
       " ('Bobholamovic/CDLab', 403),\n",
       " ('zjunlp/KnowPrompt', 403),\n",
       " ('minyoungg/pix2latent', 403),\n",
       " ('tqch/ddpm-torch', 403),\n",
       " ('huggingface/diffusion-fast', 403),\n",
       " ('Taited/clip-score', 403),\n",
       " ('ChawDoe/LeNet5-MNIST-PyTorch', 403),\n",
       " ('vt-vl-lab/Guided-pix2pix', 403),\n",
       " ('Coloquinte/torchSR', 403),\n",
       " ('JarrentWu1031/CCPL', 403),\n",
       " ('SurajDonthi/Multi-Camera-Person-Re-Identification', 403),\n",
       " ('foundation-model-stack/fms-fsdp', 403),\n",
       " ('jameschapman19/cca_zoo', 403),\n",
       " ('hityzy1122/opencv_transforms_torchvision', 403),\n",
       " ('catqaq/OpenTextClassification', 403),\n",
       " ('yangchen1997/Multi-Agent-Reinforcement-Learning', 403),\n",
       " ('Wang-Shuo/GraphRec_PyTorch', 403),\n",
       " ('gmberton/deep-visual-geo-localization-benchmark', 403),\n",
       " ('cap-ntu/ML-Model-CI', 403),\n",
       " ('amazon-science/ReFinED', 403),\n",
       " ('autonise/CRAFT-Remade', 403),\n",
       " ('kuielab/mdx-net', 403),\n",
       " ('ghimiredhikura/Complex-YOLOv3', 403),\n",
       " ('guotong1988/NL2SQL-RULE', 403),\n",
       " ('ikergarcia1996/Easy-Translate', 403),\n",
       " ('dusty-nv/jetson-voice', 403),\n",
       " ('zengqunzhao/EfficientFace', 403),\n",
       " ('divelab/GOOD', 403),\n",
       " ('PinataFarms/FEARTracker', 403),\n",
       " ('ais-lab/pl2map', 403),\n",
       " ('MLOPTPSU/FedTorch', 403),\n",
       " ('cmsflash/beauty-net', 403),\n",
       " ('SungFeng-Huang/Meta-TTS', 403),\n",
       " ('monologg/DistilKoBERT', 403),\n",
       " ('ucaszyp/STEPS', 403),\n",
       " ('Project-AgML/AgML', 403),\n",
       " ('yashsmehta/personality-prediction', 403),\n",
       " ('bupt-ai-cz/BCI', 403),\n",
       " ('TUM-DAML/gemnet_pytorch', 403),\n",
       " ('Algolzw/BSRT', 403),\n",
       " ('clin1223/VLDet', 403),\n",
       " ('luopeixiang/im2latex', 403),\n",
       " ('zubair-irshad/shapo', 403),\n",
       " ('mblondel/fenchel-young-losses', 403),\n",
       " ('signatrix/regnet', 403),\n",
       " ('valencebond/Rethinking_of_PAR', 403),\n",
       " ('object-detection-algorithm/R-CNN', 403),\n",
       " ('omerferhatt/torch2tflite', 403),\n",
       " ('emadeldeen24/AdaTime', 403),\n",
       " ('szq0214/FKD', 403),\n",
       " ('vkgo/OCRAutoScore', 403),\n",
       " ('shrubb/latent-pose-reenactment', 403),\n",
       " ('IGNF/myria3d', 403),\n",
       " ('huiyu-gao/VisFusion', 403),\n",
       " ('WillBrennan/SemanticSegmentation', 403),\n",
       " ('guanyingc/SDPS-Net', 403),\n",
       " ('david-knigge/ccnn', 403),\n",
       " ('DeepPSP/torch_ecg', 403),\n",
       " ('HEmile/storchastic', 403),\n",
       " ('DebeshJha/ResUNetPlusPlus', 403),\n",
       " ('dansuh17/alexnet-pytorch', 403),\n",
       " ('BMW-InnovationLab/BMW-Anonymization-API', 403),\n",
       " ('czczup/URST', 403),\n",
       " ('zhou13/neurvps', 403),\n",
       " ('yisun98/SOLC', 403),\n",
       " ('xavysp/TEED', 403),\n",
       " ('kangyeolk/Paint-by-Sketch', 403),\n",
       " ('GewelsJI/VPS', 403),\n",
       " ('Ai-trainee/Traffic-Sign-Recognition-PyQt5-YOLOv5-GUI', 403),\n",
       " ('liuzuxin/OSRL', 403),\n",
       " ('KennardWang/VTuber-MomoseHiyori', 403),\n",
       " ('ustcml/RecStudio', 403),\n",
       " ('Chris-hughes10/pytorch-accelerated', 403),\n",
       " ('ZihanWangKi/CrossWeigh', 403),\n",
       " ('Ha0Tang/GestureGAN', 403),\n",
       " ('nadeemlab/DeepLIIF', 403),\n",
       " ('plantnet/PlantNet-300K', 403),\n",
       " ('Pilhyeon/BaSNet-pytorch', 403),\n",
       " ('devjwsong/gpt2-dialogue-generation-pytorch', 403),\n",
       " ('zjunlp/MKGformer', 403),\n",
       " ('Penn000/SpA-GAN_for_cloud_removal', 403),\n",
       " ('matajoh/fourier_feature_nets', 403),\n",
       " ('ywyue/RoomFormer', 403),\n",
       " ('arxyzan/data2vec-pytorch', 403),\n",
       " ('LayneH/GreenMIM', 403),\n",
       " ('zudi-lin/pytorch_connectomics', 403),\n",
       " ('JieShibo/PETL-ViT', 403),\n",
       " ('Alibaba-NLP/Multi-CPR', 403),\n",
       " ('VlSomers/bpbreid', 403),\n",
       " ('hou-yz/MVDet', 403),\n",
       " ('CFGpp-diffusion/CFGpp', 403),\n",
       " ('codeslake/Color_Transfer_Histogram_Analogy', 403),\n",
       " ('kazuto1011/svm-pytorch', 403),\n",
       " ('illiterate/BertClassifier', 403),\n",
       " ('IDSIA/modern-srwm', 403),\n",
       " ('fxmeng/Pruning-Filter-in-Filter', 403),\n",
       " ('xarray-contrib/xbatcher', 403),\n",
       " ('glassroom/heinsen_routing', 403),\n",
       " ('levan92/deep_sort_realtime', 403),\n",
       " ('isLinXu/YOLOv8_Efficient', 403),\n",
       " ('liuzuxin/FSRL', 403),\n",
       " ('bharath5673/YOLOv8-3D', 403),\n",
       " ('chengchunhsu/EveryPixelMatters', 403),\n",
       " ('VainF/Diff-Pruning', 403),\n",
       " ('shinianzhihou/ChangeDetection', 403),\n",
       " ('eugenesiow/super-image', 403),\n",
       " ('Na-Z/attMPTI', 403),\n",
       " ('postBG/DTA.pytorch', 403),\n",
       " ('SforAiDl/vformer', 403),\n",
       " ('CRIPAC-DIG/GCA', 403),\n",
       " ('ABaldrati/CLIP4Cir', 403),\n",
       " ('fcakyon/small-object-detection-benchmark', 403),\n",
       " ('chenjun2hao/DDRNet.pytorch', 403),\n",
       " ('forestagostinelli/DeepCubeA', 403),\n",
       " ('jialuechen/torchquant', 403),\n",
       " ('CVI-SZU/ME-GraphAU', 403),\n",
       " ('JunlinHan/DCLGAN', 403),\n",
       " ('ChristophReich1996/MaxViT', 403),\n",
       " ('ELEKTRONN/elektronn3', 403),\n",
       " ('keishinkickback/Pytorch-RNN-text-classification', 403),\n",
       " ('leijue222/portrait-matting-unet-flask', 403),\n",
       " ('aidos-lab/pytorch-topological', 403),\n",
       " ('ViCCo-Group/thingsvision', 403),\n",
       " ('corl-team/rebased', 403),\n",
       " ('amanteur/BandSplitRNN-PyTorch', 403),\n",
       " ('janfreyberg/pytorch-revgrad', 403),\n",
       " ('woodfrog/vse_infty', 403),\n",
       " ('j-marple-dev/AYolov2', 403),\n",
       " ('miccunifi/SEARLE', 403),\n",
       " ('HaSai666/rec_pangu', 403),\n",
       " ('cuiziteng/ICCV_MAET', 403),\n",
       " ('lonePatient/TorchBlocks', 403),\n",
       " ('osainz59/Ask2Transformers', 403),\n",
       " ('sheng-z/stog', 403),\n",
       " ('AllenXiangX/SnowflakeNet', 403),\n",
       " ('fredzzhang/upt', 403),\n",
       " ('chairc/Integrated-Design-Diffusion-Model', 403),\n",
       " ('SamsungLabs/tr3d', 403),\n",
       " ('jayleicn/TVRetrieval', 403),\n",
       " ('sayakpaul/caption-upsampling', 403),\n",
       " ('NVlabs/DREAM', 403),\n",
       " ('amirhosseinh77/JetsonYolo', 403),\n",
       " ('WHU-Sigma/HyperSIGMA', 403),\n",
       " ('MarcoMeter/episodic-transformer-memory-ppo', 403),\n",
       " ('monologg/GoEmotions-pytorch', 403),\n",
       " ('customdiffusion360/custom-diffusion360', 403),\n",
       " ('audiolabs/torch-pesq', 403),\n",
       " ('BeierZhu/Prompt-align', 403),\n",
       " ('HanxunH/Unlearnable-Examples', 403),\n",
       " ('VIPL-Audio-Visual-Speech-Understanding/learn-an-effective-lip-reading-model-without-pains',\n",
       "  403),\n",
       " ('kPsarakis/Image-Forgery-Detection-CNN', 403),\n",
       " ('onpix/LCDPNet', 403),\n",
       " ('IDKiro/StarEnhancer', 403),\n",
       " ('NRCan/geo-deep-learning', 403),\n",
       " ('TIGER-AI-Lab/ImagenHub', 403),\n",
       " ('kevinzakka/torchkit', 403),\n",
       " ('Shark-NLP/CoNT', 403),\n",
       " ('ncsoft/avocodo', 403),\n",
       " ('alasdairtran/fourierflow', 403),\n",
       " ('BCV-Uniandes/AUNets', 403),\n",
       " ('haofanwang/CLIFF', 403),\n",
       " ('MarkFzp/Deep-Whole-Body-Control', 403),\n",
       " ('cosmic-cortex/pytorch-UNet', 403),\n",
       " ('DeepRank/deeprank', 403),\n",
       " ('w86763777/pytorch-image-generation-metrics', 403),\n",
       " ('gmkim-ai/Diffusion-Video-Autoencoders', 403),\n",
       " ('Ha0Tang/LGGAN', 403),\n",
       " ('tjiiv-cprg/EPro-PnP-v2', 403),\n",
       " ('rhett-chen/graspness_implementation', 403),\n",
       " ('apapiu/transformer_latent_diffusion', 403),\n",
       " ('microsoft/cliffordlayers', 403),\n",
       " ('LeapLabTHU/Pseudo-Q', 403),\n",
       " ('xlliu7/TadTR', 403),\n",
       " ('OFA-Sys/OFASys', 403),\n",
       " ('zjunlp/OntoProtein', 403),\n",
       " ('PKU-DAIR/SGL', 403),\n",
       " ('akshaydudhane16/BIPNet', 403),\n",
       " ('scaleoutsystems/fedn', 403),\n",
       " ('tub-rip/event_based_optical_flow', 403),\n",
       " ('v-iashin/MDVC', 403),\n",
       " ('amazon-science/unconditional-time-series-diffusion', 403),\n",
       " ('Lee-Gihun/MEDIAR', 403),\n",
       " ('patrick-kidger/sympytorch', 403),\n",
       " ('Photon-AI-Research/NeuralSolvers', 403),\n",
       " ('Gorilla-Lab-SCUT/tango', 403),\n",
       " ('cattaneod/CMRNet', 403),\n",
       " ('tianyu0207/PEBAL', 403),\n",
       " ('myscience/x-lstm', 403),\n",
       " ('lightning-uq-box/lightning-uq-box', 403),\n",
       " ('vvvm23/vqvae-2', 403),\n",
       " ('antocad/FocusOnDepth', 403),\n",
       " ('alvinwan/shiftresnet-cifar', 403),\n",
       " ('fhamborg/NewsMTSC', 403),\n",
       " ('Lornatang/ESRGAN-PyTorch', 403),\n",
       " ('Tengfei-Wang/DCSR', 403),\n",
       " ('ogkalu2/Merge-Stable-Diffusion-models-without-distortion', 403),\n",
       " ('caojiezhang/DATSR', 403),\n",
       " ('ktrk115/const_layout', 403),\n",
       " ('fletcherjiang/LLMEPET', 403),\n",
       " ('WindChimeRan/pytorch_multi_head_selection_re', 403),\n",
       " ('xavysp/LDC', 403),\n",
       " ('cwchenwang/NeRF-SR', 403),\n",
       " ('logancyang/loss-landscape-anim', 403),\n",
       " ('georgian-io/Knowledge-Distillation-Toolkit', 403),\n",
       " ('tsujuifu/pytorch_violet', 403),\n",
       " ('TIBHannover/GeoEstimation', 403),\n",
       " ('astro-informatics/s2fft', 403),\n",
       " ('SamsungLabs/td3d', 403),\n",
       " ('ZhikangNiu/encodec-pytorch', 403),\n",
       " ('YJiangcm/PromCSE', 403),\n",
       " ('tfaehse/DashcamCleaner', 403),\n",
       " ('ifsheldon/stannum', 403),\n",
       " ('eugeneyan/recsys-nlp-graph', 403),\n",
       " ('camlab-ethz/ConvolutionalNeuralOperator', 403),\n",
       " ('megvii-research/PMN', 403),\n",
       " ('SunghwanHong/Cost-Aggregation-transformers', 403),\n",
       " ('fuzailpalnak/building-footprint-segmentation', 403),\n",
       " ('ryul99/pytorch-project-template', 403),\n",
       " ('hahnec/torchimize', 403),\n",
       " ('yuanze-lin/REVIVE', 403),\n",
       " ('DART2022/DART', 403),\n",
       " ('archinetai/audio-data-pytorch', 403),\n",
       " ('jcwleo/curiosity-driven-exploration-pytorch', 403),\n",
       " ('clovaai/dmfont', 403),\n",
       " ('HanxunH/Active-Passive-Losses', 403),\n",
       " ('A-baoYang/alpaca-7b-chinese', 403),\n",
       " ('schatty/oprl', 403),\n",
       " ('dvlab-research/MOOD', 403),\n",
       " ('BaratiLab/Diffusion-based-Fluid-Super-resolution', 403),\n",
       " ('neu-vi/ezflow', 403),\n",
       " ('kamo-naoyuki/pytorch_convolutional_rnn', 403),\n",
       " ('syuoni/eznlp', 403),\n",
       " ('KentoNishi/torch-pitch-shift', 403),\n",
       " ('loeweX/Forward-Forward', 403),\n",
       " ('stanleylsx/entity_extractor_by_pointer', 403),\n",
       " ('zjunlp/MolGen', 403),\n",
       " ('okankop/MFF-pytorch', 403),\n",
       " ('zwx8981/UNIQUE', 403),\n",
       " ('haozheji/multigen', 403),\n",
       " ('cxy1997/3D_adapt_auto_driving', 403),\n",
       " ('zh320/realtime-semantic-segmentation-pytorch', 403),\n",
       " ('tnq177/transformers_without_tears', 403),\n",
       " ('Ha0Tang/BiGraphGAN', 403),\n",
       " ('p-giakoumoglou/pyssl', 403),\n",
       " ('Navidfoumani/ConvTran', 403),\n",
       " ('aluo-x/Learning_Neural_Acoustic_Fields', 403),\n",
       " ('pprp/captcha.Pytorch', 403),\n",
       " ('EthanRosenthal/torchmf', 403),\n",
       " ('jossalgon/StableDiffusionTelegram', 403),\n",
       " ('gist-ailab/uoais', 403),\n",
       " ('SimonRennotte/Data-Efficient-Reinforcement-Learning-with-Probabilistic-Model-Predictive-Control',\n",
       "  403),\n",
       " ('lidq92/WaDIQaM', 403),\n",
       " ('hkchengrex/Mask-Propagation', 403),\n",
       " ('warner-benjamin/commented-transformers', 403),\n",
       " ('x35f/unstable_baselines', 403),\n",
       " ('lartpang/ZoomNet', 403),\n",
       " ('lixilinx/psgd_torch', 403),\n",
       " ('aliasgharkhani/SLiMe', 403),\n",
       " ('sheffieldnlp/naacl2018-fever', 403),\n",
       " ('qq44642754a/Yolov5_ros', 403),\n",
       " ('elyha7/yoloface', 403),\n",
       " ('Yujia-Yan/Transkun', 403),\n",
       " ('MuhammadMoinFaisal/FireDetectionYOLOv8', 403),\n",
       " ('TalkUHulk/realworld-stylegan2-encoder', 403),\n",
       " ('lupantech/InterGPS', 403),\n",
       " ('microsoft/AdaMix', 403),\n",
       " ('NaJaeMin92/pytorch-DANN', 403),\n",
       " ('dahyun-kang/ifsl', 403),\n",
       " ('jackaduma/ChatGLM-LoRA-RLHF-PyTorch', 403),\n",
       " ('AndyShih12/paradigms', 403),\n",
       " ('guanhuaw/MIRTorch', 403),\n",
       " ('rllab-snu/RNR-Map', 403),\n",
       " ('ubisoft/ubisoft-laforge-daft-exprt', 403),\n",
       " ('FZJ-INM1-BDA/celldetection', 403),\n",
       " ('rasbt/faster-pytorch-blog', 403),\n",
       " ('zzxslp/SoM-LLaVA', 403),\n",
       " ('declare-lab/dialogue-understanding', 403),\n",
       " ('DebeshJha/ResUNetPlusPlus-with-CRF-and-TTA', 403),\n",
       " ('emilemathieu/pvae', 403),\n",
       " ('Pilhyeon/WTAL-Uncertainty-Modeling', 403),\n",
       " ('dptech-corp/Uni-Core', 403),\n",
       " ('Green-Wood/BTTR', 403),\n",
       " ('cceyda/torchserve-dashboard', 403),\n",
       " ('zhejz/HPTR', 403),\n",
       " ('dvlab-research/Ref-NPR', 403),\n",
       " ('BradyFU/DVG', 403),\n",
       " ('jcwang123/BA-Transformer', 403),\n",
       " ('UM-ARM-Lab/pytorch_volumetric', 403),\n",
       " ('zhiyiYo/Alpha-Gobang-Zero', 403),\n",
       " ('Wuyxin/DIR-GNN', 403),\n",
       " ('thu-coai/DA-Transformer', 403),\n",
       " ('ksw0306/WaveVAE', 403),\n",
       " ('alibaba/graphlearn-for-pytorch', 403),\n",
       " ('sunanhe/MKT', 403),\n",
       " ('lucidrains/pytorch-custom-utils', 403),\n",
       " ('hellloxiaotian/ADNet', 403),\n",
       " ('JunlinHan/BID', 403),\n",
       " ('hyliush/deep-time-series', 403),\n",
       " ('zhangbaijin/MemoryNet', 403),\n",
       " ('Qrange-group/SUR-adapter', 403),\n",
       " ('FENRlR/MB-iSTFT-VITS2', 403),\n",
       " ('neosapience/editts', 403),\n",
       " ('jahongir7174/YOLOv8-pt', 403),\n",
       " ('moein-shariatnia/Pix2Seq', 403),\n",
       " ('wjun0830/CGDETR', 403),\n",
       " ('KiseKloset/DM-VTON', 403),\n",
       " ('svjan5/medtype', 403),\n",
       " ('AlbertSuarez/object-cut', 403),\n",
       " ('malllabiisc/ProteinGCN', 403),\n",
       " ('aphp/edsnlp', 403),\n",
       " ('dvl-tum/SUSHI', 403),\n",
       " ('wenzhu23333/Federated-Learning', 403),\n",
       " ('cwx-worst-one/EAT', 403),\n",
       " ('khanld/ASR-Wav2vec-Finetune', 403),\n",
       " ('BarqueroGerman/BeLFusion', 403),\n",
       " ('codeslake/PVDNet', 403),\n",
       " ('Jingliang-Duan/DSAC-v1', 403),\n",
       " ('yingkunwu/R-YOLOv4', 403),\n",
       " ('hsvgbkhgbv/SQDDPG', 403),\n",
       " ('jeffreysijuntan/lloco', 403),\n",
       " ('fmahoudeau/ShelfNet-Human-Pose-Estimation', 403),\n",
       " ('pprp/captcha_identify.pytorch', 403),\n",
       " ('shibing624/nerpy', 403),\n",
       " ('AntoineTheb/RNN-RL', 403),\n",
       " ('zhanghengdev/MutualGuide', 403),\n",
       " ('kunheek/style-aware-discriminator', 403),\n",
       " ('JadHADDAD92/covid-mask-detector', 403),\n",
       " ('mengmengliu1998/LAformer', 403),\n",
       " ('narumiruna/efficientnet-pytorch', 403),\n",
       " ('HankYe/PAGCP', 403),\n",
       " ('Jiahao000/MosaicFusion', 403),\n",
       " ('Git-123-Hub/maddpg-pettingzoo-pytorch', 403),\n",
       " ('The-FinAI/trials', 403),\n",
       " ('IIM-TTIJ/MVA2023SmallObjectDetection4SpottingBirds', 403),\n",
       " ('YongWookHa/swin-transformer-ocr', 403),\n",
       " ('kc-ml2/SimpleDreamer', 403),\n",
       " ('TARTRL/TiKick', 403),\n",
       " ('Vermeille/Torchelie', 403),\n",
       " ('mingukkang/elatentlpips', 403),\n",
       " ('TsingZ0/FedALA', 403),\n",
       " ('jspenmar/monodepth_benchmark', 403),\n",
       " ('epistoteles/TensorHue', 403),\n",
       " ('seonghyeonye/Flipped-Learning', 403),\n",
       " ('dr-costas/mad-twinnet', 403),\n",
       " ('c-yn/AdaIR', 403),\n",
       " ('V2AI/EFG', 403),\n",
       " ('newlei/LR-GCCF', 403),\n",
       " ('TsingZ0/HtFLlib', 403),\n",
       " ('sh0416/llama-classification', 403),\n",
       " ('S-aiueo32/srntt-pytorch', 403),\n",
       " ('xiaosu-zhu/McQuic', 403),\n",
       " ('ilya-shenbin/RecVAE', 403),\n",
       " ('Yi-Shi94/AMDM', 403),\n",
       " ('xuarehere/yolo_series_deepsort_pytorch', 403),\n",
       " ('CHENGY12/DMML', 403),\n",
       " ('Agwave/PDF-Resume-Information-Extraction', 403),\n",
       " ('hellloxiaotian/CFSRCNN', 403),\n",
       " ('Labbeti/aac-datasets', 403),\n",
       " ('zhongyuchen/few-shot-text-classification', 403),\n",
       " ('LiYingwei/ShapeTextureDebiasedTraining', 403),\n",
       " ('zanilzanzan/FuseNet_PyTorch', 403),\n",
       " ('Audio-WestlakeU/McNet', 403),\n",
       " ('vlfom/RNCDL', 403),\n",
       " ('Shengfeng233/PINN-for-NS-equation', 403),\n",
       " ('Little-Podi/AiATrack', 403),\n",
       " ('pomonam/kronfluence', 403),\n",
       " ('plkmo/NLP_Toolkit', 403),\n",
       " ('c-yn/SFNet', 403),\n",
       " ('gmftbyGMFTBY/OpenDialog', 403),\n",
       " ('guyyariv/TempoTokens', 403),\n",
       " ('RQ-Wu/UnderwaterRanker', 403),\n",
       " ('Tengfei-Wang/external-internal-inpainting', 403),\n",
       " ('Audio-WestlakeU/audiossl', 403),\n",
       " ('BlindDPS/blind-dps', 403),\n",
       " ('Orange-OpenSource/Cool-Chic', 403),\n",
       " ('xmindflow/DAEFormer', 403),\n",
       " ('DLR-RM/rl-trained-agents', 403),\n",
       " ('astra-vision/PODA', 403),\n",
       " ('gatsby2016/Augmentation-PyTorch-Transforms', 403),\n",
       " ('oakink/OakInk', 403),\n",
       " ('NJUNLP/knn-box', 403),\n",
       " ('purvaten/FLEX', 403),\n",
       " ('Tony-Y/cgnn', 403),\n",
       " ('csiro-robotics/LoGG3D-Net', 403),\n",
       " ('interestingLSY/swiftLLM', 403),\n",
       " ('sgrvinod/chess-transformers', 403),\n",
       " ('JunlinHan/YOCO', 403),\n",
       " ('ShuweiShao/AF-SfMLearner', 403),\n",
       " ('ddehueck/pytorch-neat', 403),\n",
       " ('GewelsJI/DGNet', 403),\n",
       " ('jiseongHAN/Super-Mario-RL', 403),\n",
       " ('TorchMoE/MoE-Infinity', 403),\n",
       " ('HolyWu/vs-rife', 403),\n",
       " ('dki-lab/GrailQA', 403),\n",
       " ('guanyingc/PS-FCN', 403),\n",
       " ('kpthedev/ez-text2video', 403),\n",
       " ('hoya012/carrier-of-tricks-for-classification-pytorch', 403),\n",
       " ('xudejing/video-clip-order-prediction', 403),\n",
       " ('tranleanh/mobilenets-ssd-pytorch', 403),\n",
       " ('kaistmm/Audio-Mamba-AuM', 403),\n",
       " ('elvisyjlin/SpatialAttentionGAN', 403),\n",
       " ('ajhamdi/MVTN', 403),\n",
       " ('NormXU/ERNIE-Layout-Pytorch', 403),\n",
       " ('pairlab/SlotFormer', 403),\n",
       " ('XinyuanLiao/ComplexNN', 403),\n",
       " ('threedle/3DHighlighter', 403),\n",
       " ('bytesc/Image_Recognition_WebGUI', 403),\n",
       " ('lyutyuh/ASP', 403),\n",
       " ('bshall/acoustic-model', 403),\n",
       " ('jordddan/Pruning-LLMs', 403),\n",
       " ('Gusb3ll/Tsuki', 403),\n",
       " ('anibali/margipose', 403),\n",
       " ('funcwj/voice-filter', 403),\n",
       " ('fdbtrs/CR-FIQA', 403),\n",
       " ('naseemap47/YOLO-NAS', 403),\n",
       " ('zjunlp/HVPNeT', 403),\n",
       " ('OliverRensu/D-iGPT', 403),\n",
       " ('georg-wolflein/chesscog', 403),\n",
       " ('thunlp/Prompt-Transferability', 403),\n",
       " ('luchangli03/export_llama_to_onnx', 403),\n",
       " ('ga642381/SpeechPrompt', 403),\n",
       " ('jiaowoguanren0615/MobileNetV4', 403),\n",
       " ('eric-ai-lab/PEViT', 403),\n",
       " ('louisoutin/yolov5_torchserve', 403),\n",
       " ('openpifpaf/openpifpafwebdemo', 403),\n",
       " ('TuragaLab/DECODE', 403),\n",
       " ('Shanghai-Digital-Brain-Laboratory/DB-Football', 403),\n",
       " ('xiaoyufenfei/ESNet', 403),\n",
       " ('Eric-Canas/qrdet', 403),\n",
       " ('filipbasara0/simple-diffusion', 403),\n",
       " ('Solacex/CCM', 403),\n",
       " ('Berry-Wu/Visualization', 403),\n",
       " ('ViTAE-Transformer/P3M-Net', 403),\n",
       " ('lorenmt/minimal-isaac-gym', 403),\n",
       " ('Haiyang-W/CAGroup3D', 403),\n",
       " ('bwconrad/vit-finetune', 403),\n",
       " ('arvindrajan92/DTrOCR', 403),\n",
       " ('mike9251/simswap-inference-pytorch', 403),\n",
       " ('stevewongv/DSC-PyTorch', 403),\n",
       " ('zhirui-gao/Deep-Template-Matching', 403),\n",
       " ('Coderx7/SimpleNet', 403),\n",
       " ('soochan-lee/MR-GAN', 403),\n",
       " ('epwalsh/nlp-models', 403),\n",
       " ('buxihuo/OW-YOLO', 403),\n",
       " ('wdphy16/stat-mech-van', 403),\n",
       " ('mush42/optispeech', 403),\n",
       " ('clearhanhui/LearnLibTorch', 403),\n",
       " ('CoinCheung/gdGPT', 403),\n",
       " ('vitrioil/Speech-Separation', 403),\n",
       " ('lucidrains/vit-pytorch', 403),\n",
       " ('graphdeco-inria/gaussian-splatting', 403),\n",
       " ('davidsandberg/facenet', 403),\n",
       " ('alicevision/Meshroom', 403),\n",
       " ('xuebinqin/U-2-Net', 403),\n",
       " ('PaddlePaddle/models', 403),\n",
       " ('clovaai/donut', 403),\n",
       " ('Layout-Parser/layout-parser', 403),\n",
       " ('hzwer/ECCV2022-RIFE', 403),\n",
       " ('STVIR/pysot', 403),\n",
       " ('NVlabs/neuralangelo', 403),\n",
       " ('katanaml/sparrow', 403),\n",
       " ('fundamentalvision/BEVFormer', 403),\n",
       " ('richzhang/colorization', 403),\n",
       " ('google-research/scenic', 403),\n",
       " ('xinghaochen/awesome-hand-pose-estimation', 403),\n",
       " ('neuralmagic/deepsparse', 403),\n",
       " ('Tencent/PocketFlow', 403),\n",
       " ('roboflow/sports', 403),\n",
       " ('harleyszhang/cv_note', 403),\n",
       " ('vietanhdev/anylabeling', 403),\n",
       " ('IDEA-Research/DINO', 403),\n",
       " ('junshutang/Make-It-3D', 403),\n",
       " ('cambrian-mllm/cambrian', 403),\n",
       " ('kha-white/manga-ocr', 403),\n",
       " ('PaddlePaddle/Research', 403),\n",
       " ('adobe/antialiased-cnns', 403),\n",
       " ('GaParmar/img2img-turbo', 403),\n",
       " ('roboflow/awesome-openai-vision-api-experiments', 403),\n",
       " ('spla-tam/SplaTAM', 403),\n",
       " ('Anything-of-anything/Anything-3D', 403),\n",
       " ('rese1f/StableVideo', 403),\n",
       " ('muskie82/MonoGS', 403),\n",
       " ('minivision-ai/Silent-Face-Anti-Spoofing', 403),\n",
       " ('QingyongHu/RandLA-Net', 403),\n",
       " ('yatengLG/ISAT_with_segment_anything', 403),\n",
       " ('tensorlayer/HyperPose', 403),\n",
       " ('poloclub/diffusiondb', 403),\n",
       " ('atulapra/Emotion-detection', 403),\n",
       " ('openpifpaf/openpifpaf', 403),\n",
       " ...]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetch_readmes(repos_df.full_name.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rubik\\Documents\\CS573_Documentation_Quality\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#read csv\n",
    "import pandas as pd\n",
    "repos_df = pd.read_csv(\"repositories.csv\")\n",
    "\n",
    "readme_text = []\n",
    "\n",
    "#for every repo in the csv, get the readme\n",
    "for index,row in repos_df.iterrows():\n",
    "    repo_full_name = row[\"full_name\"]\n",
    "    safe_name = repo_full_name.replace(\"/\", \"_\")\n",
    "\n",
    "    #open the readme file\n",
    "    try:\n",
    "        with open(f\"readmes/{safe_name}.md\", \"r\", encoding=\"utf-8\") as f:\n",
    "            readme = f.read()\n",
    "            readme_text.append(readme)\n",
    "    except:\n",
    "        readme_text.append(None)\n",
    "\n",
    "repos_df[\"readme_text\"] = readme_text\n",
    "repos_df = repos_df.dropna(subset=[\"readme_text\"])\n",
    "\n",
    "from readmepp import ReadMe\n",
    "\n",
    "predictor = ReadMe(lang='en')\n",
    "predictor.model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "#count the occurences of \"^- \" of each readme\n",
    "lists_count = repos_df[\"readme_text\"].str.count(r\"^- \", flags=re.MULTILINE)\n",
    "#log then normalize it\n",
    "lists_count = np.log1p(1 + lists_count)\n",
    "lists_count = (lists_count - lists_count.min()) / (lists_count.max() - lists_count.min())\n",
    "repos_df[\"lists_count\"] = lists_count\n",
    "\n",
    "#count hypperlinks\n",
    "hyperlinks_count = repos_df[\"readme_text\"].str.count(r\"http[s]?:\\/\\/(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\", flags=re.MULTILINE)\n",
    "#log then normalize it\n",
    "hyperlinks_count = np.log1p(1 + hyperlinks_count)\n",
    "hyperlinks_count = (hyperlinks_count - hyperlinks_count.min()) / (hyperlinks_count.max() - hyperlinks_count.min())\n",
    "repos_df[\"hyperlinks_count\"] = hyperlinks_count\n",
    "\n",
    "#number of images ending in .png, .jpg, .jpeg, .gif (url or local path) in .md ir .rst\n",
    "#[image] (https://example.com/image.png)\n",
    "#image:: https://example.com/image.png\n",
    "#<.*src.*=.*\\.(png|jpg|jpeg|gif|svg).*>\n",
    "images_count = repos_df[\"readme_text\"].str.count(r\"!\\[.*\\]\\(.*\\.(png|jpg|jpeg|gif|svg)\\)\", flags=re.MULTILINE) + \\\n",
    "            repos_df[\"readme_text\"].str.count(r\"image::.*\\.(png|jpg|jpeg|gif|svg)\", flags=re.MULTILINE) + \\\n",
    "            repos_df[\"readme_text\"].str.count(r\"<.*src.*=.*\\.(png|jpg|jpeg|gif|svg).*>\", flags=re.MULTILINE)\n",
    "#log then normalize it\n",
    "images_count = np.log1p(1 + images_count)\n",
    "images_count = (images_count - images_count.min()) / (images_count.max() - images_count.min())\n",
    "repos_df[\"images_count\"] = images_count\n",
    "\n",
    "#number of code blocks divide by 2 and round down\n",
    "code_blocks_count = (repos_df[\"readme_text\"].str.count(r\"^```\", flags=re.MULTILINE) // 2).astype(int)\n",
    "#log then normalize it\n",
    "code_blocks_count = np.log1p(1 + code_blocks_count)\n",
    "code_blocks_count = (code_blocks_count - code_blocks_count.min()) / (code_blocks_count.max() - code_blocks_count.min())\n",
    "repos_df[\"code_blocks_count\"] = code_blocks_count\n",
    "\n",
    "#number of new lines with content\n",
    "content_lines_count = repos_df[\"readme_text\"].str.count(r\"^.*[^\\s]\", flags=re.MULTILINE)\n",
    "#log then normalize it\n",
    "content_lines_count = np.log1p(1 + content_lines_count)\n",
    "content_lines_count = (content_lines_count - content_lines_count.min()) / (content_lines_count.max() - content_lines_count.min())\n",
    "repos_df[\"content_lines_count\"] = content_lines_count\n",
    "\n",
    "\n",
    "\n",
    "# Flesch Reading Score\n",
    "#textstat.flesch_reading_ease(test_data)\n",
    "import textstat\n",
    "flesch_reading_scores = repos_df[\"readme_text\"].apply(lambda x: textstat.flesch_reading_ease(x) if x else None)\n",
    "#normalize\n",
    "flesch_reading_scores = (flesch_reading_scores - flesch_reading_scores.min()) / (flesch_reading_scores.max() - flesch_reading_scores.min())\n",
    "repos_df[\"flesch_reading_scores\"] = flesch_reading_scores\n",
    "\n",
    "\n",
    "# number of headers\n",
    "headers_count = repos_df[\"readme_text\"].str.count(r\"#+\", flags=re.MULTILINE)\n",
    "#log then normalize\n",
    "headers_count = np.log1p(1 + headers_count)\n",
    "headers_count = (headers_count - headers_count.min()) / (headers_count.max() - headers_count.min())\n",
    "repos_df[\"headers_count\"] = headers_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "repos_df[\"readmepp\"] = repos_df[\"readme_text\"].apply(lambda x: predictor.predict(x) if x else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting-started\n",
      "contributing\n",
      "license\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def parse_markdown_headers(text):\n",
    "    '''Parse markdown text into a list of (header_level, header_text, content) tuples'''\n",
    "    lines = text.split('\\n')\n",
    "    headers = []\n",
    "    current_header = None\n",
    "    current_content = []\n",
    "    current_level = None\n",
    "    for line in lines:\n",
    "        header_match = re.match(r'^(#{1,3})\\s+(.*)', line)\n",
    "        if header_match:\n",
    "            # Save the current content if any\n",
    "            if current_header is not None:\n",
    "                headers.append((current_level, current_header, '\\n'.join(current_content)))\n",
    "            # Start a new header\n",
    "            current_level = len(header_match.group(1))\n",
    "            current_header = header_match.group(2)\n",
    "            current_content = []\n",
    "        else:\n",
    "            if current_header is not None:\n",
    "                current_content.append(line)\n",
    "    # Save the last header content\n",
    "    if current_header is not None:\n",
    "        headers.append((current_level, current_header, '\\n'.join(current_content)))\n",
    "    return headers\n",
    "\n",
    "def process_readme(text, keywords_subset,content_subset, levels=(1,2,3)):\n",
    "    \"\"\"\n",
    "    Process a single README text.\n",
    "    Returns:\n",
    "        header_found: True if at least one header keyword is found in headers of specified levels.\n",
    "        percentage: Percentage of keywords found in content under matching headers.\n",
    "    \"\"\"\n",
    "    headers = parse_markdown_headers(text)\n",
    "    # Initialize\n",
    "    header_found = False\n",
    "    content_text = ''\n",
    "    index = 0\n",
    "    for level, header_text, content in headers:\n",
    "        if level in levels:\n",
    "            # Check if any of the keywords are present in the header text\n",
    "            if any(kw.lower() in header_text.lower() for kw in keywords_subset):\n",
    "                header_found = True\n",
    "                #then collect all header with lower level and stop untill equal or higher level\n",
    "                content_text += '\\n' + content\n",
    "                for next_level, next_header_text, next_content in headers[index+1:]:\n",
    "                    if next_level <= level:\n",
    "                        break\n",
    "                    content_text += '\\n' + next_content\n",
    "\n",
    "        index += 1\n",
    "    # If no matching headers, percentage is 0\n",
    "    if not header_found or not keywords_subset:\n",
    "        return header_found, 0.0\n",
    "    # Now compute the percentage of keywords found in content_text\n",
    "    total_keywords = len(content_subset)\n",
    "    found_keywords = sum(1 for kw in content_subset if kw.lower() in content_text.lower())\n",
    "    percentage = found_keywords / total_keywords\n",
    "    return header_found, percentage\n",
    "\n",
    "# Modify your main loop\n",
    "readme_type = \"gh\"  # \"gh\" or \"hf\"\n",
    "for keyword_category in keywords[\"keywords\"]:\n",
    "    print(keyword_category)\n",
    "\n",
    "    # Initialize columns\n",
    "    header_column = f\"header_{keyword_category}\"\n",
    "    percentage_column = f\"percentage_{keyword_category}\"\n",
    "    #repos_df[header_column] = False  # This will be the header_found boolean\n",
    "    #repos_df[percentage_column] = 0.0  # This will be the keyword percentage\n",
    "\n",
    "    keywords_subset = keywords[\"keywords\"][keyword_category][f\"{readme_type}-header-keywords\"]\n",
    "    content_subset = keywords[\"keywords\"][keyword_category][f\"{readme_type}-content-keywords\"]\n",
    "\n",
    "    # Apply the function to each row\n",
    "    def process_row(row):\n",
    "        text = row['readme_text']\n",
    "        header_found, percentage = process_readme(text, keywords_subset, content_subset)\n",
    "        return pd.Series({header_column: header_found, percentage_column: percentage})\n",
    "\n",
    "    repos_df[[header_column, percentage_column]] = repos_df.apply(process_row, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependant Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stars_ = np.log1p(repos_df[\"stargazers_count\"])\n",
    "stars_ = (stars_ - stars_.min()) / (stars_.max() - stars_.min())\n",
    "repos_df['stargazers_count_normalized'] = stars_\n",
    "\n",
    "forks_ = np.log1p(repos_df[\"forks_count\"])\n",
    "forks_ = (forks_ - forks_.min()) / (forks_.max() - forks_.min())\n",
    "repos_df['forks_count_normalized'] = forks_\n",
    "\n",
    "# watchers_ = np.log1p(repos_df[\"watchers_count\"])\n",
    "# watchers_ = (watchers_ - watchers_.min()) / (watchers_.max() - watchers_.min())\n",
    "# repos_df['watchers_count_normalized'] = watchers_\n",
    "\n",
    "heurstics = repos_df[\"forks_count\"]/repos_df[\"stargazers_count\"]\n",
    "heurstics = (heurstics - heurstics.min()) / (heurstics.max() - heurstics.min())\n",
    "repos_df['onboarding_normalized'] = heurstics\n",
    "\n",
    "repos_df[['readmepp_normalized']] = (repos_df[['readmepp']] - 1)/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation between lists_count and stargazers_count_normalized: 0.106\n",
      "Pearson correlation between hyperlinks_count and stargazers_count_normalized: 0.319\n",
      "Pearson correlation between images_count and stargazers_count_normalized: 0.197\n",
      "Pearson correlation between code_blocks_count and stargazers_count_normalized: 0.038\n",
      "Pearson correlation between content_lines_count and stargazers_count_normalized: 0.176\n",
      "Pearson correlation between headers_count and stargazers_count_normalized: 0.102\n",
      "Pearson correlation between flesch_reading_scores and stargazers_count_normalized: -0.023\n",
      "Pearson correlation between readmepp_normalized and stargazers_count_normalized: 0.02\n",
      "Pearson correlation between header_getting-started and stargazers_count_normalized: -0.016\n",
      "Pearson correlation between header_contributing and stargazers_count_normalized: 0.078\n",
      "Pearson correlation between header_license and stargazers_count_normalized: 0.029\n",
      "Pearson correlation between percentage_getting-started and stargazers_count_normalized: 0.027\n",
      "Pearson correlation between percentage_contributing and stargazers_count_normalized: 0.06\n",
      "Pearson correlation between percentage_license and stargazers_count_normalized: 0.041\n",
      "Pearson correlation between lists_count and forks_count_normalized: 0.043\n",
      "Pearson correlation between hyperlinks_count and forks_count_normalized: 0.24\n",
      "Pearson correlation between images_count and forks_count_normalized: 0.138\n",
      "Pearson correlation between code_blocks_count and forks_count_normalized: -0.07\n",
      "Pearson correlation between content_lines_count and forks_count_normalized: 0.059\n",
      "Pearson correlation between headers_count and forks_count_normalized: -0.002\n",
      "Pearson correlation between flesch_reading_scores and forks_count_normalized: -0.039\n",
      "Pearson correlation between readmepp_normalized and forks_count_normalized: -0.024\n",
      "Pearson correlation between header_getting-started and forks_count_normalized: -0.105\n",
      "Pearson correlation between header_contributing and forks_count_normalized: 0.047\n",
      "Pearson correlation between header_license and forks_count_normalized: 0.01\n",
      "Pearson correlation between percentage_getting-started and forks_count_normalized: -0.034\n",
      "Pearson correlation between percentage_contributing and forks_count_normalized: 0.046\n",
      "Pearson correlation between percentage_license and forks_count_normalized: 0.025\n",
      "Pearson correlation between lists_count and onboarding_normalized: -0.055\n",
      "Pearson correlation between hyperlinks_count and onboarding_normalized: -0.064\n",
      "Pearson correlation between images_count and onboarding_normalized: -0.048\n",
      "Pearson correlation between code_blocks_count and onboarding_normalized: -0.111\n",
      "Pearson correlation between content_lines_count and onboarding_normalized: -0.132\n",
      "Pearson correlation between headers_count and onboarding_normalized: -0.105\n",
      "Pearson correlation between flesch_reading_scores and onboarding_normalized: -0.02\n",
      "Pearson correlation between readmepp_normalized and onboarding_normalized: -0.051\n",
      "Pearson correlation between header_getting-started and onboarding_normalized: -0.106\n",
      "Pearson correlation between header_contributing and onboarding_normalized: -0.024\n",
      "Pearson correlation between header_license and onboarding_normalized: 0.001\n",
      "Pearson correlation between percentage_getting-started and onboarding_normalized: -0.074\n",
      "Pearson correlation between percentage_contributing and onboarding_normalized: -0.004\n",
      "Pearson correlation between percentage_license and onboarding_normalized: -0.001\n",
      "Pearson correlation between percentage_getting-started and stargazers_count_normalized: 0.068\n",
      "Pearson correlation between percentage_contributing and stargazers_count_normalized: 0.018\n",
      "Pearson correlation between percentage_license and stargazers_count_normalized: 0.059\n",
      "Pearson correlation between percentage_getting-started and forks_count_normalized: 0.07\n",
      "Pearson correlation between percentage_contributing and forks_count_normalized: 0.035\n",
      "Pearson correlation between percentage_license and forks_count_normalized: 0.052\n",
      "Pearson correlation between percentage_getting-started and onboarding_normalized: -0.002\n",
      "Pearson correlation between percentage_contributing and onboarding_normalized: 0.04\n",
      "Pearson correlation between percentage_license and onboarding_normalized: -0.004\n"
     ]
    }
   ],
   "source": [
    "#Independant Columns normalized between 0 and 1\n",
    "count_independent_columns = [\"lists_count\", \"hyperlinks_count\", \"images_count\", \"code_blocks_count\", \"content_lines_count\", \"headers_count\"]\n",
    "#score Indecpend column\n",
    "score_independent_columns = [\"flesch_reading_scores\" , \"readmepp_normalized\"]\n",
    "#keyword independant columns#binary 0 or 1\n",
    "keyword_independent_columns = [\"header_getting-started\", \"header_contributing\", \"header_license\"]\n",
    "content_indenpendant_columns = [\"percentage_getting-started\", \"percentage_contributing\", \"percentage_license\"]\n",
    "\n",
    "dependant_columns = [\"stargazers_count_normalized\", \"forks_count_normalized\", \"onboarding_normalized\"]\n",
    "#dependant_columns = dependant_columns[-1:]\n",
    "\n",
    "\n",
    "independent_columns = count_independent_columns + score_independent_columns + keyword_independent_columns + content_indenpendant_columns\n",
    "\n",
    "\n",
    "score_dict={\"counts\":{ column:{} for column in count_independent_columns}\n",
    "            ,\n",
    "       \"keyword\":{ column:{} for column in keyword_independent_columns},\n",
    "       \"content\": { column:{} for column in content_indenpendant_columns},\n",
    "       \"scores\":{ column:{} for column in score_independent_columns}\n",
    "       }\n",
    "\n",
    "\n",
    "repos_df = repos_df.dropna(subset=independent_columns + dependant_columns)\n",
    "# Pearson correlation\n",
    "from sklearn.feature_selection import r_regression\n",
    "\n",
    "for dependant in dependant_columns:\n",
    "    score = r_regression(repos_df[independent_columns].values, repos_df[dependant].values)\n",
    "\n",
    "    for i, column in enumerate(independent_columns):\n",
    "        print(f\"Pearson correlation between {column} and {dependant}: {round(score[i],3)}\")\n",
    "\n",
    "        if column in count_independent_columns:\n",
    "            score_dict[\"counts\"][column][dependant] = round(score[i],3)\n",
    "        elif column in keyword_independent_columns:\n",
    "            score_dict[\"keyword\"][column][dependant] = round(score[i],3)\n",
    "        elif column in score_independent_columns:\n",
    "            score_dict[\"scores\"][column][dependant] = round(score[i],3)\n",
    "\n",
    "for dependant in dependant_columns:\n",
    "    for i in range(len(content_indenpendant_columns)):\n",
    "        content_col = content_indenpendant_columns[i]\n",
    "        keyword_col = keyword_independent_columns[i]\n",
    "        repos_df_sub = repos_df[repos_df[keyword_col] == True]\n",
    "        \n",
    "        score = r_regression(repos_df_sub[[content_col]].values, repos_df_sub[dependant].values)\n",
    "        print(f\"Pearson correlation between {content_col} and {dependant}: {round(score[0],3)}\")\n",
    "        score_dict[\"content\"][content_col][dependant] = round(score[0],3)\n",
    "    \n",
    "\n",
    "\n",
    "# Cliffs Delta\n",
    "\n",
    "\n",
    "#Fishers Exact Test\n",
    "# import scipy.stats as stats\n",
    "\n",
    "# odd_ratio, p_value = stats.fisher_exact([repos_df[\"content_lines_count\"], repos_df[\"stargazers_count_normalized\"]])\n",
    "\n",
    "\n",
    "#logistic regression feature important extraction\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# X = repos_df[independent_columns].values\n",
    "# y = repos_df[dependant_columns[0]].values\n",
    "\n",
    "# clf = LinearRegression().fit(X, y)\n",
    "# clf.coef_  # logistic regression feature importance extraction\n",
    "\n",
    "# for i, column in enumerate(independent_columns):\n",
    "#     print(f\"Linear regression coefficient for {column}: {round(clf.coef_[i],3)}\")\n",
    "\n",
    "#     if column in count_independent_columns:\n",
    "#         score_dict[\"counts\"][column]['LinearRegression'] = round(clf.coef_[i],3)\n",
    "#     elif column in keyword_independent_columns:\n",
    "#         score_dict[\"keyword\"][column]['LinearRegression'] = round(clf.coef_[i],3)\n",
    "#     elif column in score_independent_columns:\n",
    "#         score_dict[\"scores\"][column]['LinearRegression'] = round(clf.coef_[i],3)\n",
    "\n",
    "\n",
    "# random forest feature importance extraction\n",
    "\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# clf = RandomForestRegressor().fit(X, y)\n",
    "# clf.feature_importances_  # random forest feature importance extraction\n",
    "\n",
    "# for i, column in enumerate(independent_columns):\n",
    "#     print(f\"Random forest feature importance for {column}: {round(clf.feature_importances_[i],3)}\")\n",
    "\n",
    "#     if column in count_independent_columns:\n",
    "#         score_dict[\"counts\"][column][\"Random Forest\"] = round(clf.feature_importances_[i],3)\n",
    "#     elif column in keyword_independent_columns:\n",
    "#         score_dict[\"keyword\"][column][\"Random Forest\"] = round(clf.feature_importances_[i],3)\n",
    "#     elif column in score_independent_columns:\n",
    "#         score_dict[\"scores\"][column][\"Random Forest\"] = round(clf.feature_importances_[i],3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>stargazers_count_normalized</th>\n",
       "      <th>forks_count_normalized</th>\n",
       "      <th>onboarding_normalized</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_type</th>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">counts</th>\n",
       "      <th>code_blocks_count</th>\n",
       "      <td>0.038</td>\n",
       "      <td>-0.070</td>\n",
       "      <td>-0.111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>content_lines_count</th>\n",
       "      <td>0.176</td>\n",
       "      <td>0.059</td>\n",
       "      <td>-0.132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>headers_count</th>\n",
       "      <td>0.102</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hyperlinks_count</th>\n",
       "      <td>0.319</td>\n",
       "      <td>0.240</td>\n",
       "      <td>-0.064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images_count</th>\n",
       "      <td>0.197</td>\n",
       "      <td>0.138</td>\n",
       "      <td>-0.048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lists_count</th>\n",
       "      <td>0.106</td>\n",
       "      <td>0.043</td>\n",
       "      <td>-0.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">keyword</th>\n",
       "      <th>header_contributing</th>\n",
       "      <td>0.078</td>\n",
       "      <td>0.047</td>\n",
       "      <td>-0.024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>header_getting-started</th>\n",
       "      <td>-0.016</td>\n",
       "      <td>-0.105</td>\n",
       "      <td>-0.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>header_license</th>\n",
       "      <td>0.029</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">content</th>\n",
       "      <th>percentage_contributing</th>\n",
       "      <td>0.018</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>percentage_getting-started</th>\n",
       "      <td>0.068</td>\n",
       "      <td>0.070</td>\n",
       "      <td>-0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>percentage_license</th>\n",
       "      <td>0.059</td>\n",
       "      <td>0.052</td>\n",
       "      <td>-0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">scores</th>\n",
       "      <th>flesch_reading_scores</th>\n",
       "      <td>-0.023</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>-0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>readmepp_normalized</th>\n",
       "      <td>0.020</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>-0.051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       stargazers_count_normalized  \\\n",
       "score_type index                                                     \n",
       "counts     code_blocks_count                                 0.038   \n",
       "           content_lines_count                               0.176   \n",
       "           headers_count                                     0.102   \n",
       "           hyperlinks_count                                  0.319   \n",
       "           images_count                                      0.197   \n",
       "           lists_count                                       0.106   \n",
       "keyword    header_contributing                               0.078   \n",
       "           header_getting-started                           -0.016   \n",
       "           header_license                                    0.029   \n",
       "content    percentage_contributing                           0.018   \n",
       "           percentage_getting-started                        0.068   \n",
       "           percentage_license                                0.059   \n",
       "scores     flesch_reading_scores                            -0.023   \n",
       "           readmepp_normalized                               0.020   \n",
       "\n",
       "                                       forks_count_normalized  \\\n",
       "score_type index                                                \n",
       "counts     code_blocks_count                           -0.070   \n",
       "           content_lines_count                          0.059   \n",
       "           headers_count                               -0.002   \n",
       "           hyperlinks_count                             0.240   \n",
       "           images_count                                 0.138   \n",
       "           lists_count                                  0.043   \n",
       "keyword    header_contributing                          0.047   \n",
       "           header_getting-started                      -0.105   \n",
       "           header_license                               0.010   \n",
       "content    percentage_contributing                      0.035   \n",
       "           percentage_getting-started                   0.070   \n",
       "           percentage_license                           0.052   \n",
       "scores     flesch_reading_scores                       -0.039   \n",
       "           readmepp_normalized                         -0.024   \n",
       "\n",
       "                                       onboarding_normalized  \n",
       "score_type index                                              \n",
       "counts     code_blocks_count                          -0.111  \n",
       "           content_lines_count                        -0.132  \n",
       "           headers_count                              -0.105  \n",
       "           hyperlinks_count                           -0.064  \n",
       "           images_count                               -0.048  \n",
       "           lists_count                                -0.055  \n",
       "keyword    header_contributing                        -0.024  \n",
       "           header_getting-started                     -0.106  \n",
       "           header_license                              0.001  \n",
       "content    percentage_contributing                     0.040  \n",
       "           percentage_getting-started                 -0.002  \n",
       "           percentage_license                         -0.004  \n",
       "scores     flesch_reading_scores                      -0.020  \n",
       "           readmepp_normalized                        -0.051  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert to pands dataframe with mulit index\n",
    "# rows is the score type\n",
    "# columns is the feature (with subcolumns for each method)\n",
    "\n",
    "score_df = pd.DataFrame()\n",
    "for score_type, score_data in score_dict.items():\n",
    "    df_sub = pd.DataFrame(score_data).T\n",
    "    df_sub = df_sub.reset_index()\n",
    "    df_sub.insert(0, \"score_type\", score_type)\n",
    "    \n",
    "    score_df = pd.concat([score_df, df_sub], axis=0)\n",
    "\n",
    "sort_array = [2] * len(content_indenpendant_columns) + [0] * len(count_independent_columns) + [1] * len(keyword_independent_columns) + [3] * len(score_independent_columns)\n",
    "df_group = score_df.groupby([\"score_type\",'index']).mean()\n",
    "df_group[\"sort\"] = sort_array\n",
    "df_group = df_group.sort_values(by=[\"sort\"]).drop(columns=\"sort\")\n",
    "df_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting-started: 6281\n",
      "contributing: 2573\n",
      "license: 2283\n"
     ]
    }
   ],
   "source": [
    "# repos_df[\"header_getting-started\"].sum()\n",
    "# repos_df[\"header_contributing\"].sum()\n",
    "# repos_df[\"header_license\"].sum()\n",
    "print(f\"getting-started: {repos_df['header_getting-started'].sum()}\")\n",
    "print(f\"contributing: {repos_df['header_contributing'].sum()}\")\n",
    "print(f\"license: {repos_df['header_license'].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mreadmepp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ReadMe\n\u001b[0;32m      3\u001b[0m predictor \u001b[38;5;241m=\u001b[39m ReadMe(lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Rubik\\Documents\\CS573_Documentation_Quality\\.venv\\Lib\\site-packages\\readmepp\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer, AutoModelForSequenceClassification\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mReadMe\u001b[39;00m:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "from readmepp import ReadMe\n",
    "\n",
    "predictor = ReadMe(lang='en')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mpredictor\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhello how are you\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'predictor' is not defined"
     ]
    }
   ],
   "source": [
    "predictor.predict(\"hello how are you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "#reload torch module\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip3 install torch torchvision --index-url https://download.pytorch.org/whl/cu124"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
